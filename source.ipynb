{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"data/1301.3781v3.pdf\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fa49273b7b4838b01fbf99a536db79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page_num': 0,\n",
       "  'page_char_count': 2824,\n",
       "  'page_word_count': 445,\n",
       "  'page_sentences_count': 17,\n",
       "  'page_tokens_count': 706.0,\n",
       "  'text': 'Efﬁcient Estimation of Word Representations in Vector Space Tomas Mikolov Google Inc., Mountain View, CA tmikolov@google.com Kai Chen Google Inc., Mountain View, CA kaichen@google.com Greg Corrado Google Inc., Mountain View, CA gcorrado@google.com Jeffrey Dean Google Inc., Mountain View, CA jeff@google.com Abstract We propose two novel model architectures for computing continuous vector repre- sentations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previ- ously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art perfor- mance on our test set for measuring syntactic and semantic word similarities. 1 Introduction Many current NLP systems and techniques treat words as atomic units - there is no notion of similar- ity between words, as these are represented as indices in a vocabulary. This choice has several good reasons - simplicity, robustness and the observation that simple models trained on huge amounts of data outperform complex systems trained on less data. An example is the popular N-gram model used for statistical language modeling - today, it is possible to train N-grams on virtually all available data (trillions of words [3]). However, the simple techniques are at their limits in many tasks. For example, the amount of relevant in-domain data for automatic speech recognition is limited - the performance is usually dominated by the size of high quality transcribed speech data (often just millions of words). In machine translation, the existing corpora for many languages contain only a few billions of words or less. Thus, there are situations where simple scaling up of the basic techniques will not result in any signiﬁcant progress, and we have to focus on more advanced techniques. With progress of machine learning techniques in recent years, it has become possible to train more complex models on much larger data set, and they typically outperform the simple models. Probably the most successful concept is to use distributed representations of words [10]. For example, neural network based language models signiﬁcantly outperform N-gram models [1, 27, 17]. 1.1 Goals of the Paper The main goal of this paper is to introduce techniques that can be used for learning high-quality word vectors from huge data sets with billions of words, and with millions of words in the vocabulary. As far as we know, none of the previously proposed architectures has been successfully trained on more 1 arXiv:1301.3781v3  [cs.CL]  7 Sep 2013'},\n",
       " {'page_num': 1,\n",
       "  'page_char_count': 3977,\n",
       "  'page_word_count': 608,\n",
       "  'page_sentences_count': 23,\n",
       "  'page_tokens_count': 994.25,\n",
       "  'text': 'than a few hundred of millions of words, with a modest dimensionality of the word vectors between 50 - 100. We use recently proposed techniques for measuring the quality of the resulting vector representa- tions, with the expectation that not only will similar words tend to be close to each other, but that words can have multiple degrees of similarity [20]. This has been observed earlier in the context of inﬂectional languages - for example, nouns can have multiple word endings, and if we search for similar words in a subspace of the original vector space, it is possible to ﬁnd words that have similar endings [13, 14]. Somewhat surprisingly, it was found that similarity of word representations goes beyond simple syntactic regularities. Using a word offset technique where simple algebraic operations are per- formed on the word vectors, it was shown for example that vector(”King”) - vector(”Man”) + vec- tor(”Woman”) results in a vector that is closest to the vector representation of the word Queen [20]. In this paper, we try to maximize accuracy of these vector operations by developing new model architectures that preserve the linear regularities among words. We design a new comprehensive test set for measuring both syntactic and semantic regularities1, and show that many such regularities can be learned with high accuracy. Moreover, we discuss how training time and accuracy depends on the dimensionality of the word vectors and on the amount of the training data. 1.2 Previous Work Representation of words as continuous vectors has a long history [10, 26, 8]. A very popular model architecture for estimating neural network language model (NNLM) was proposed in [1], where a feedforward neural network with a linear projection layer and a non-linear hidden layer was used to learn jointly the word vector representation and a statistical language model. This work has been followed by many others. Another interesting architecture of NNLM was presented in [13, 14], where the word vectors are ﬁrst learned using neural network with a single hidden layer. The word vectors are then used to train the NNLM. Thus, the word vectors are learned even without constructing the full NNLM. In this work, we directly extend this architecture, and focus just on the ﬁrst step where the word vectors are learned using a simple model. It was later shown that the word vectors can be used to signiﬁcantly improve and simplify many NLP applications [4, 5, 29]. Estimation of the word vectors itself was performed using different model architectures and trained on various corpora [4, 29, 23, 19, 9], and some of the resulting word vectors were made available for future research and comparison2. However, as far as we know, these architectures were signiﬁcantly more computationally expensive for training than the one proposed in [13], with the exception of certain version of log-bilinear model where diagonal weight matrices are used [23]. 2 Model Architectures Many different types of models were proposed for estimating continuous representations of words, including the well-known Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA). In this paper, we focus on distributed representations of words learned by neural networks, as it was previously shown that they perform signiﬁcantly better than LSA for preserving linear regularities among words [20, 31]; LDA moreover becomes computationally very expensive on large data sets. Similar to [18], to compare different model architectures we deﬁne ﬁrst the computational complex- ity of a model as the number of parameters that need to be accessed to fully train the model. Next, we will try to maximize the accuracy, while minimizing the computational complexity. 1The test set is available at www.fit.vutbr.cz/˜imikolov/rnnlm/word-test.v1.txt 2http://ronan.collobert.com/senna/ http://metaoptimize.com/projects/wordreprs/ http://www.fit.vutbr.cz/˜imikolov/rnnlm/ http://ai.stanford.edu/˜ehhuang/ 2'},\n",
       " {'page_num': 2,\n",
       "  'page_char_count': 3989,\n",
       "  'page_word_count': 696,\n",
       "  'page_sentences_count': 28,\n",
       "  'page_tokens_count': 997.25,\n",
       "  'text': 'For all the following models, the training complexity is proportional to O = E × T × Q, (1) where E is number of the training epochs, T is the number of the words in the training set and Q is deﬁned further for each model architecture. Common choice is E = 3 − 50 and T up to one billion. All models are trained using stochastic gradient descent and backpropagation [26]. 2.1 Feedforward Neural Net Language Model (NNLM) The probabilistic feedforward neural network language model has been proposed in [1]. It consists of input, projection, hidden and output layers. At the input layer, N previous words are encoded using 1-of-V coding, where V is size of the vocabulary. The input layer is then projected to a projection layer P that has dimensionality N × D, using a shared projection matrix. As only N inputs are active at any given time, composition of the projection layer is a relatively cheap operation. The NNLM architecture becomes complex for computation between the projection and the hidden layer, as values in the projection layer are dense. For a common choice of N = 10, the size of the projection layer (P) might be 500 to 2000, while the hidden layer size H is typically 500 to 1000 units. Moreover, the hidden layer is used to compute probability distribution over all the words in the vocabulary, resulting in an output layer with dimensionality V . Thus, the computational complexity per each training example is Q = N × D + N × D × H + H × V, (2) where the dominating term is H × V . However, several practical solutions were proposed for avoiding it; either using hierarchical versions of the softmax [25, 23, 18], or avoiding normalized models completely by using models that are not normalized during training [4, 9]. With binary tree representations of the vocabulary, the number of output units that need to be evaluated can go down to around log2(V ). Thus, most of the complexity is caused by the term N × D × H. In our models, we use hierarchical softmax where the vocabulary is represented as a Huffman binary tree. This follows previous observations that the frequency of words works well for obtaining classes in neural net language models [16]. Huffman trees assign short binary codes to frequent words, and this further reduces the number of output units that need to be evaluated: while balanced binary tree would require log2(V ) outputs to be evaluated, the Huffman tree based hierarchical softmax requires only about log2(Unigram perplexity(V )). For example when the vocabulary size is one million words, this results in about two times speedup in evaluation. While this is not crucial speedup for neural network LMs as the computational bottleneck is in the N ×D×H term, we will later propose architectures that do not have hidden layers and thus depend heavily on the efﬁciency of the softmax normalization. 2.2 Recurrent Neural Net Language Model (RNNLM) Recurrent neural network based language model has been proposed to overcome certain limitations of the feedforward NNLM, such as the need to specify the context length (the order of the model N), and because theoretically RNNs can efﬁciently represent more complex patterns than the shallow neural networks [15, 2]. The RNN model does not have a projection layer; only input, hidden and output layer. What is special for this type of model is the recurrent matrix that connects hidden layer to itself, using time-delayed connections. This allows the recurrent model to form some kind of short term memory, as information from the past can be represented by the hidden layer state that gets updated based on the current input and the state of the hidden layer in the previous time step. The complexity per training example of the RNN model is Q = H × H + H × V, (3) where the word representations D have the same dimensionality as the hidden layer H. Again, the term H × V can be efﬁciently reduced to H × log2(V ) by using hierarchical softmax. Most of the complexity then comes from H × H. 3'},\n",
       " {'page_num': 3,\n",
       "  'page_char_count': 3972,\n",
       "  'page_word_count': 668,\n",
       "  'page_sentences_count': 23,\n",
       "  'page_tokens_count': 993.0,\n",
       "  'text': '2.3 Parallel Training of Neural Networks To train models on huge data sets, we have implemented several models on top of a large-scale distributed framework called DistBelief [6], including the feedforward NNLM and the new models proposed in this paper. The framework allows us to run multiple replicas of the same model in parallel, and each replica synchronizes its gradient updates through a centralized server that keeps all the parameters. For this parallel training, we use mini-batch asynchronous gradient descent with an adaptive learning rate procedure called Adagrad [7]. Under this framework, it is common to use one hundred or more model replicas, each using many CPU cores at different machines in a data center. 3 New Log-linear Models In this section, we propose two new model architectures for learning distributed representations of words that try to minimize computational complexity. The main observation from the previous section was that most of the complexity is caused by the non-linear hidden layer in the model. While this is what makes neural networks so attractive, we decided to explore simpler models that might not be able to represent the data as precisely as neural networks, but can possibly be trained on much more data efﬁciently. The new architectures directly follow those proposed in our earlier work [13, 14], where it was found that neural network language model can be successfully trained in two steps: ﬁrst, continuous word vectors are learned using simple model, and then the N-gram NNLM is trained on top of these distributed representations of words. While there has been later substantial amount of work that focuses on learning word vectors, we consider the approach proposed in [13] to be the simplest one. Note that related models have been proposed also much earlier [26, 8]. 3.1 Continuous Bag-of-Words Model The ﬁrst proposed architecture is similar to the feedforward NNLM, where the non-linear hidden layer is removed and the projection layer is shared for all words (not just the projection matrix); thus, all words get projected into the same position (their vectors are averaged). We call this archi- tecture a bag-of-words model as the order of words in the history does not inﬂuence the projection. Furthermore, we also use words from the future; we have obtained the best performance on the task introduced in the next section by building a log-linear classiﬁer with four future and four history words at the input, where the training criterion is to correctly classify the current (middle) word. Training complexity is then Q = N × D + D × log2(V ). (4) We denote this model further as CBOW, as unlike standard bag-of-words model, it uses continuous distributed representation of the context. The model architecture is shown at Figure 1. Note that the weight matrix between the input and the projection layer is shared for all word positions in the same way as in the NNLM. 3.2 Continuous Skip-gram Model The second architecture is similar to CBOW, but instead of predicting the current word based on the context, it tries to maximize classiﬁcation of a word based on another word in the same sentence. More precisely, we use each current word as an input to a log-linear classiﬁer with continuous projection layer, and predict words within a certain range before and after the current word. We found that increasing the range improves quality of the resulting word vectors, but it also increases the computational complexity. Since the more distant words are usually less related to the current word than those close to it, we give less weight to the distant words by sampling less from those words in our training examples. The training complexity of this architecture is proportional to Q = C × (D + D × log2(V )), (5) where C is the maximum distance of the words. Thus, if we choose C = 5, for each training word we will select randomly a number R in range < 1; C >, and then use R words from history and 4'},\n",
       " {'page_num': 4,\n",
       "  'page_char_count': 2680,\n",
       "  'page_word_count': 549,\n",
       "  'page_sentences_count': 17,\n",
       "  'page_tokens_count': 670.0,\n",
       "  'text': 'w(t-2) w(t+1) w(t-1) w(t+2) w(t) SUM        INPUT         PROJECTION         OUTPUT w(t)           INPUT         PROJECTION      OUTPUT w(t-2) w(t-1) w(t+1) w(t+2)                    CBOW                                                   Skip-gram Figure 1: New model architectures. The CBOW architecture predicts the current word based on the context, and the Skip-gram predicts surrounding words given the current word. R words from the future of the current word as correct labels. This will require us to do R × 2 word classiﬁcations, with the current word as input, and each of the R + R words as output. In the following experiments, we use C = 10. 4 Results To compare the quality of different versions of word vectors, previous papers typically use a table showing example words and their most similar words, and understand them intuitively. Although it is easy to show that word France is similar to Italy and perhaps some other countries, it is much more challenging when subjecting those vectors in a more complex similarity task, as follows. We follow previous observation that there can be many different types of similarities between words, for example, word big is similar to bigger in the same sense that small is similar to smaller. Example of another type of relationship can be word pairs big - biggest and small - smallest [20]. We further denote two pairs of words with the same relationship as a question, as we can ask: ”What is the word that is similar to small in the same sense as biggest is similar to big?” Somewhat surprisingly, these questions can be answered by performing simple algebraic operations with the vector representation of words. To ﬁnd a word that is similar to small in the same sense as biggest is similar to big, we can simply compute vector X = vector(”biggest”)−vector(”big”)+ vector(”small”). Then, we search in the vector space for the word closest to X measured by cosine distance, and use it as the answer to the question (we discard the input question words during this search). When the word vectors are well trained, it is possible to ﬁnd the correct answer (word smallest) using this method. Finally, we found that when we train high dimensional word vectors on a large amount of data, the resulting vectors can be used to answer very subtle semantic relationships between words, such as a city and the country it belongs to, e.g. France is to Paris as Germany is to Berlin. Word vectors with such semantic relationships could be used to improve many existing NLP applications, such as machine translation, information retrieval and question answering systems, and may enable other future applications yet to be invented. 5'},\n",
       " {'page_num': 5,\n",
       "  'page_char_count': 3490,\n",
       "  'page_word_count': 548,\n",
       "  'page_sentences_count': 22,\n",
       "  'page_tokens_count': 872.5,\n",
       "  'text': 'Table 1: Examples of ﬁve types of semantic and nine types of syntactic questions in the Semantic- Syntactic Word Relationship test set. Type of relationship Word Pair 1 Word Pair 2 Common capital city Athens Greece Oslo Norway All capital cities Astana Kazakhstan Harare Zimbabwe Currency Angola kwanza Iran rial City-in-state Chicago Illinois Stockton California Man-Woman brother sister grandson granddaughter Adjective to adverb apparent apparently rapid rapidly Opposite possibly impossibly ethical unethical Comparative great greater tough tougher Superlative easy easiest lucky luckiest Present Participle think thinking read reading Nationality adjective Switzerland Swiss Cambodia Cambodian Past tense walking walked swimming swam Plural nouns mouse mice dollar dollars Plural verbs work works speak speaks 4.1 Task Description To measure quality of the word vectors, we deﬁne a comprehensive test set that contains ﬁve types of semantic questions, and nine types of syntactic questions. Two examples from each category are shown in Table 1. Overall, there are 8869 semantic and 10675 syntactic questions. The questions in each category were created in two steps: ﬁrst, a list of similar word pairs was created manually. Then, a large list of questions is formed by connecting two word pairs. For example, we made a list of 68 large American cities and the states they belong to, and formed about 2.5K questions by picking two word pairs at random. We have included in our test set only single token words, thus multi-word entities are not present (such as New York). We evaluate the overall accuracy for all question types, and for each question type separately (se- mantic, syntactic). Question is assumed to be correctly answered only if the closest word to the vector computed using the above method is exactly the same as the correct word in the question; synonyms are thus counted as mistakes. This also means that reaching 100% accuracy is likely to be impossible, as the current models do not have any input information about word morphology. However, we believe that usefulness of the word vectors for certain applications should be positively correlated with this accuracy metric. Further progress can be achieved by incorporating information about structure of words, especially for the syntactic questions. 4.2 Maximization of Accuracy We have used a Google News corpus for training the word vectors. This corpus contains about 6B tokens. We have restricted the vocabulary size to 1 million most frequent words. Clearly, we are facing time constrained optimization problem, as it can be expected that both using more data and higher dimensional word vectors will improve the accuracy. To estimate the best choice of model architecture for obtaining as good as possible results quickly, we have ﬁrst evaluated models trained on subsets of the training data, with vocabulary restricted to the most frequent 30k words. The results using the CBOW architecture with different choice of word vector dimensionality and increasing amount of the training data are shown in Table 2. It can be seen that after some point, adding more dimensions or adding more training data provides diminishing improvements. So, we have to increase both vector dimensionality and the amount of the training data together. While this observation might seem trivial, it must be noted that it is currently popular to train word vectors on relatively large amounts of data, but with insufﬁcient size 6'},\n",
       " {'page_num': 6,\n",
       "  'page_char_count': 3174,\n",
       "  'page_word_count': 535,\n",
       "  'page_sentences_count': 22,\n",
       "  'page_tokens_count': 793.5,\n",
       "  'text': 'Table 2: Accuracy on subset of the Semantic-Syntactic Word Relationship test set, using word vectors from the CBOW architecture with limited vocabulary. Only questions containing words from the most frequent 30k words are used. Dimensionality / Training words 24M 49M 98M 196M 391M 783M 50 13.4 15.7 18.6 19.1 22.5 23.2 100 19.4 23.1 27.8 28.7 33.4 32.2 300 23.2 29.2 35.3 38.6 43.7 45.9 600 24.0 30.1 36.5 40.8 46.6 50.4 Table 3: Comparison of architectures using models trained on the same data, with 640-dimensional word vectors. The accuracies are reported on our Semantic-Syntactic Word Relationship test set, and on the syntactic relationship test set of [20] Model Semantic-Syntactic Word Relationship test set MSR Word Relatedness Architecture Semantic Accuracy [%] Syntactic Accuracy [%] Test Set [20] RNNLM 9 36 35 NNLM 23 53 47 CBOW 24 64 61 Skip-gram 55 59 56 (such as 50 - 100). Given Equation 4, increasing amount of training data twice results in about the same increase of computational complexity as increasing vector size twice. For the experiments reported in Tables 2 and 4, we used three training epochs with stochastic gradi- ent descent and backpropagation. We chose starting learning rate 0.025 and decreased it linearly, so that it approaches zero at the end of the last training epoch. 4.3 Comparison of Model Architectures First we compare different model architectures for deriving the word vectors using the same training data and using the same dimensionality of 640 of the word vectors. In the further experiments, we use full set of questions in the new Semantic-Syntactic Word Relationship test set, i.e. unrestricted to the 30k vocabulary. We also include results on a test set introduced in [20] that focuses on syntactic similarity between words3. The training data consists of several LDC corpora and is described in detail in [18] (320M words, 82K vocabulary). We used these data to provide a comparison to a previously trained recurrent neural network language model that took about 8 weeks to train on a single CPU. We trained a feed- forward NNLM with the same number of 640 hidden units using the DistBelief parallel training [6], using a history of 8 previous words (thus, the NNLM has more parameters than the RNNLM, as the projection layer has size 640 × 8). In Table 3, it can be seen that the word vectors from the RNN (as used in [20]) perform well mostly on the syntactic questions. The NNLM vectors perform signiﬁcantly better than the RNN - this is not surprising, as the word vectors in the RNNLM are directly connected to a non-linear hidden layer. The CBOW architecture works better than the NNLM on the syntactic tasks, and about the same on the semantic one. Finally, the Skip-gram architecture works slightly worse on the syntactic task than the CBOW model (but still better than the NNLM), and much better on the semantic part of the test than all the other models. Next, we evaluated our models trained using one CPU only and compared the results against publicly available word vectors. The comparison is given in Table 4. The CBOW model was trained on subset 3We thank Geoff Zweig for providing us the test set. 7'},\n",
       " {'page_num': 7,\n",
       "  'page_char_count': 2197,\n",
       "  'page_word_count': 392,\n",
       "  'page_sentences_count': 11,\n",
       "  'page_tokens_count': 549.25,\n",
       "  'text': 'Table 4: Comparison of publicly available word vectors on the Semantic-Syntactic Word Relation- ship test set, and word vectors from our models. Full vocabularies are used. Model Vector Training Accuracy [%] Dimensionality words Semantic Syntactic Total Collobert-Weston NNLM 50 660M 9.3 12.3 11.0 Turian NNLM 50 37M 1.4 2.6 2.1 Turian NNLM 200 37M 1.4 2.2 1.8 Mnih NNLM 50 37M 1.8 9.1 5.8 Mnih NNLM 100 37M 3.3 13.2 8.8 Mikolov RNNLM 80 320M 4.9 18.4 12.7 Mikolov RNNLM 640 320M 8.6 36.5 24.6 Huang NNLM 50 990M 13.3 11.6 12.3 Our NNLM 20 6B 12.9 26.4 20.3 Our NNLM 50 6B 27.9 55.8 43.2 Our NNLM 100 6B 34.2 64.5 50.8 CBOW 300 783M 15.5 53.1 36.1 Skip-gram 300 783M 50.0 55.9 53.3 Table 5: Comparison of models trained for three epochs on the same data and models trained for one epoch. Accuracy is reported on the full Semantic-Syntactic data set. Model Vector Training Accuracy [%] Training time Dimensionality words [days] Semantic Syntactic Total 3 epoch CBOW 300 783M 15.5 53.1 36.1 1 3 epoch Skip-gram 300 783M 50.0 55.9 53.3 3 1 epoch CBOW 300 783M 13.8 49.9 33.6 0.3 1 epoch CBOW 300 1.6B 16.1 52.6 36.1 0.6 1 epoch CBOW 600 783M 15.4 53.3 36.2 0.7 1 epoch Skip-gram 300 783M 45.6 52.2 49.2 1 1 epoch Skip-gram 300 1.6B 52.2 55.1 53.8 2 1 epoch Skip-gram 600 783M 56.7 54.5 55.5 2.5 of the Google News data in about a day, while training time for the Skip-gram model was about three days. For experiments reported further, we used just one training epoch (again, we decrease the learning rate linearly so that it approaches zero at the end of training). Training a model on twice as much data using one epoch gives comparable or better results than iterating over the same data for three epochs, as is shown in Table 5, and provides additional small speedup. 4.4 Large Scale Parallel Training of Models As mentioned earlier, we have implemented various models in a distributed framework called Dis- tBelief. Below we report the results of several models trained on the Google News 6B data set, with mini-batch asynchronous gradient descent and the adaptive learning rate procedure called Ada- grad [7]. We used 50 to 100 model replicas during the training. The number of CPU cores is an 8'},\n",
       " {'page_num': 8,\n",
       "  'page_char_count': 2983,\n",
       "  'page_word_count': 496,\n",
       "  'page_sentences_count': 20,\n",
       "  'page_tokens_count': 745.75,\n",
       "  'text': 'Table 6: Comparison of models trained using the DistBelief distributed framework. Note that training of NNLM with 1000-dimensional vectors would take too long to complete. Model Vector Training Accuracy [%] Training time Dimensionality words [days x CPU cores] Semantic Syntactic Total NNLM 100 6B 34.2 64.5 50.8 14 x 180 CBOW 1000 6B 57.3 68.9 63.7 2 x 140 Skip-gram 1000 6B 66.1 65.1 65.6 2.5 x 125 Table 7: Comparison and combination of models on the Microsoft Sentence Completion Challenge. Architecture Accuracy [%] 4-gram [32] 39 Average LSA similarity [32] 49 Log-bilinear model [24] 54.8 RNNLMs [19] 55.4 Skip-gram 48.0 Skip-gram + RNNLMs 58.9 estimate since the data center machines are shared with other production tasks, and the usage can ﬂuctuate quite a bit. Note that due to the overhead of the distributed framework, the CPU usage of the CBOW model and the Skip-gram model are much closer to each other than their single-machine implementations. The result are reported in Table 6. 4.5 Microsoft Research Sentence Completion Challenge The Microsoft Sentence Completion Challenge has been recently introduced as a task for advancing language modeling and other NLP techniques [32]. This task consists of 1040 sentences, where one word is missing in each sentence and the goal is to select word that is the most coherent with the rest of the sentence, given a list of ﬁve reasonable choices. Performance of several techniques has been already reported on this set, including N-gram models, LSA-based model [32], log-bilinear model [24] and a combination of recurrent neural networks that currently holds the state of the art performance of 55.4% accuracy on this benchmark [19]. We have explored the performance of Skip-gram architecture on this task. First, we train the 640- dimensional model on 50M words provided in [32]. Then, we compute score of each sentence in the test set by using the unknown word at the input, and predict all surrounding words in a sentence. The ﬁnal sentence score is then the sum of these individual predictions. Using the sentence scores, we choose the most likely sentence. A short summary of some previous results together with the new results is presented in Table 7. While the Skip-gram model itself does not perform on this task better than LSA similarity, the scores from this model are complementary to scores obtained with RNNLMs, and a weighted combination leads to a new state of the art result 58.9% accuracy (59.2% on the development part of the set and 58.7% on the test part of the set). 5 Examples of the Learned Relationships Table 8 shows words that follow various relationships. We follow the approach described above: the relationship is deﬁned by subtracting two word vectors, and the result is added to another word. Thus for example, Paris - France + Italy = Rome. As it can be seen, accuracy is quite good, although there is clearly a lot of room for further improvements (note that using our accuracy metric that 9'},\n",
       " {'page_num': 9,\n",
       "  'page_char_count': 3823,\n",
       "  'page_word_count': 595,\n",
       "  'page_sentences_count': 24,\n",
       "  'page_tokens_count': 955.75,\n",
       "  'text': 'Table 8: Examples of the word pair relationships, using the best word vectors from Table 4 (Skip- gram model trained on 783M words with 300 dimensionality). Relationship Example 1 Example 2 Example 3 France - Paris Italy: Rome Japan: Tokyo Florida: Tallahassee big - bigger small: larger cold: colder quick: quicker Miami - Florida Baltimore: Maryland Dallas: Texas Kona: Hawaii Einstein - scientist Messi: midﬁelder Mozart: violinist Picasso: painter Sarkozy - France Berlusconi: Italy Merkel: Germany Koizumi: Japan copper - Cu zinc: Zn gold: Au uranium: plutonium Berlusconi - Silvio Sarkozy: Nicolas Putin: Medvedev Obama: Barack Microsoft - Windows Google: Android IBM: Linux Apple: iPhone Microsoft - Ballmer Google: Yahoo IBM: McNealy Apple: Jobs Japan - sushi Germany: bratwurst France: tapas USA: pizza assumes exact match, the results in Table 8 would score only about 60%). We believe that word vectors trained on even larger data sets with larger dimensionality will perform signiﬁcantly better, and will enable the development of new innovative applications. Another way to improve accuracy is to provide more than one example of the relationship. By using ten examples instead of one to form the relationship vector (we average the individual vectors together), we have observed improvement of accuracy of our best models by about 10% absolutely on the semantic-syntactic test. It is also possible to apply the vector operations to solve different tasks. For example, we have observed good accuracy for selecting out-of-the-list words, by computing average vector for a list of words, and ﬁnding the most distant word vector. This is a popular type of problems in certain human intelligence tests. Clearly, there is still a lot of discoveries to be made using these techniques. 6 Conclusion In this paper we studied the quality of vector representations of words derived by various models on a collection of syntactic and semantic language tasks. We observed that it is possible to train high quality word vectors using very simple model architectures, compared to the popular neural network models (both feedforward and recurrent). Because of the much lower computational complexity, it is possible to compute very accurate high dimensional word vectors from a much larger data set. Using the DistBelief distributed framework, it should be possible to train the CBOW and Skip-gram models even on corpora with one trillion words, for basically unlimited size of the vocabulary. That is several orders of magnitude larger than the best previously published results for similar models. An interesting task where the word vectors have recently been shown to signiﬁcantly outperform the previous state of the art is the SemEval-2012 Task 2 [11]. The publicly available RNN vectors were used together with other techniques to achieve over 50% increase in Spearman’s rank correlation over the previous best result [31]. The neural network based word vectors were previously applied to many other NLP tasks, for example sentiment analysis [12] and paraphrase detection [28]. It can be expected that these applications can beneﬁt from the model architectures described in this paper. Our ongoing work shows that the word vectors can be successfully applied to automatic extension of facts in Knowledge Bases, and also for veriﬁcation of correctness of existing facts. Results from machine translation experiments also look very promising. In the future, it would be also interesting to compare our techniques to Latent Relational Analysis [30] and others. We believe that our comprehensive test set will help the research community to improve the existing techniques for estimating the word vectors. We also expect that high quality word vectors will become an important building block for future NLP applications. 10'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def text_formatter(text : str)-> str:\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def open_and_read_pdf(pdf_path : str)-> list[dict]:\n",
    "    doc= fitz.open(pdf_path)\n",
    "    pages_and_text = []\n",
    "    for page_num , page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text=text)\n",
    "        pages_and_text.append({\"page_num\": page_num , \n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentences_count\": len(text.split(\". \")),\n",
    "                                \"page_tokens_count\": len(text)/4,\n",
    "                                \"text\": text})\n",
    "    return pages_and_text\n",
    "pages_and_text = open_and_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_text[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(pages_and_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentences_count</th>\n",
       "      <th>page_tokens_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2824</td>\n",
       "      <td>445</td>\n",
       "      <td>17</td>\n",
       "      <td>706.00</td>\n",
       "      <td>Efﬁcient Estimation of Word Representations in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3977</td>\n",
       "      <td>608</td>\n",
       "      <td>23</td>\n",
       "      <td>994.25</td>\n",
       "      <td>than a few hundred of millions of words, with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3989</td>\n",
       "      <td>696</td>\n",
       "      <td>28</td>\n",
       "      <td>997.25</td>\n",
       "      <td>For all the following models, the training com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3972</td>\n",
       "      <td>668</td>\n",
       "      <td>23</td>\n",
       "      <td>993.00</td>\n",
       "      <td>2.3 Parallel Training of Neural Networks To tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2680</td>\n",
       "      <td>549</td>\n",
       "      <td>17</td>\n",
       "      <td>670.00</td>\n",
       "      <td>w(t-2) w(t+1) w(t-1) w(t+2) w(t) SUM        IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3490</td>\n",
       "      <td>548</td>\n",
       "      <td>22</td>\n",
       "      <td>872.50</td>\n",
       "      <td>Table 1: Examples of ﬁve types of semantic and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3174</td>\n",
       "      <td>535</td>\n",
       "      <td>22</td>\n",
       "      <td>793.50</td>\n",
       "      <td>Table 2: Accuracy on subset of the Semantic-Sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2197</td>\n",
       "      <td>392</td>\n",
       "      <td>11</td>\n",
       "      <td>549.25</td>\n",
       "      <td>Table 4: Comparison of publicly available word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2983</td>\n",
       "      <td>496</td>\n",
       "      <td>20</td>\n",
       "      <td>745.75</td>\n",
       "      <td>Table 6: Comparison of models trained using th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3823</td>\n",
       "      <td>595</td>\n",
       "      <td>24</td>\n",
       "      <td>955.75</td>\n",
       "      <td>Table 8: Examples of the word pair relationshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>3535</td>\n",
       "      <td>528</td>\n",
       "      <td>129</td>\n",
       "      <td>883.75</td>\n",
       "      <td>7 Follow-Up Work After the initial version of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2089</td>\n",
       "      <td>299</td>\n",
       "      <td>94</td>\n",
       "      <td>522.25</td>\n",
       "      <td>[18] T. Mikolov, A. Deoras, D. Povey, L. Burge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_num  page_char_count  page_word_count  page_sentences_count  \\\n",
       "0          0             2824              445                    17   \n",
       "1          1             3977              608                    23   \n",
       "2          2             3989              696                    28   \n",
       "3          3             3972              668                    23   \n",
       "4          4             2680              549                    17   \n",
       "5          5             3490              548                    22   \n",
       "6          6             3174              535                    22   \n",
       "7          7             2197              392                    11   \n",
       "8          8             2983              496                    20   \n",
       "9          9             3823              595                    24   \n",
       "10        10             3535              528                   129   \n",
       "11        11             2089              299                    94   \n",
       "\n",
       "    page_tokens_count                                               text  \n",
       "0              706.00  Efﬁcient Estimation of Word Representations in...  \n",
       "1              994.25  than a few hundred of millions of words, with ...  \n",
       "2              997.25  For all the following models, the training com...  \n",
       "3              993.00  2.3 Parallel Training of Neural Networks To tr...  \n",
       "4              670.00  w(t-2) w(t+1) w(t-1) w(t+2) w(t) SUM        IN...  \n",
       "5              872.50  Table 1: Examples of ﬁve types of semantic and...  \n",
       "6              793.50  Table 2: Accuracy on subset of the Semantic-Sy...  \n",
       "7              549.25  Table 4: Comparison of publicly available word...  \n",
       "8              745.75  Table 6: Comparison of models trained using th...  \n",
       "9              955.75  Table 8: Examples of the word pair relationshi...  \n",
       "10             883.75  7 Follow-Up Work After the initial version of ...  \n",
       "11             522.25  [18] T. Mikolov, A. Deoras, D. Povey, L. Burge...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentences_count</th>\n",
       "      <th>page_tokens_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.50</td>\n",
       "      <td>3227.75</td>\n",
       "      <td>529.92</td>\n",
       "      <td>35.83</td>\n",
       "      <td>806.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.61</td>\n",
       "      <td>680.73</td>\n",
       "      <td>112.17</td>\n",
       "      <td>36.37</td>\n",
       "      <td>170.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2089.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>522.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.75</td>\n",
       "      <td>2788.00</td>\n",
       "      <td>483.25</td>\n",
       "      <td>19.25</td>\n",
       "      <td>697.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.50</td>\n",
       "      <td>3332.00</td>\n",
       "      <td>541.50</td>\n",
       "      <td>22.50</td>\n",
       "      <td>833.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.25</td>\n",
       "      <td>3860.25</td>\n",
       "      <td>598.25</td>\n",
       "      <td>25.00</td>\n",
       "      <td>965.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.00</td>\n",
       "      <td>3989.00</td>\n",
       "      <td>696.00</td>\n",
       "      <td>129.00</td>\n",
       "      <td>997.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  page_char_count  page_word_count  page_sentences_count  \\\n",
       "count     12.00            12.00            12.00                 12.00   \n",
       "mean       5.50          3227.75           529.92                 35.83   \n",
       "std        3.61           680.73           112.17                 36.37   \n",
       "min        0.00          2089.00           299.00                 11.00   \n",
       "25%        2.75          2788.00           483.25                 19.25   \n",
       "50%        5.50          3332.00           541.50                 22.50   \n",
       "75%        8.25          3860.25           598.25                 25.00   \n",
       "max       11.00          3989.00           696.00                129.00   \n",
       "\n",
       "       page_tokens_count  \n",
       "count              12.00  \n",
       "mean              806.94  \n",
       "std               170.18  \n",
       "min               522.25  \n",
       "25%               697.00  \n",
       "50%               833.00  \n",
       "75%               965.06  \n",
       "max               997.25  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ this is some thing i am writing.,\n",
       " this is another sentence.,\n",
       " this is the last sentence.]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "doc = nlp(\" this is some thing i am writing. this is another sentence. this is the last sentence.\")\n",
    "assert len(list(doc.sents)) == 3\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_num': 0,\n",
       " 'page_char_count': 2824,\n",
       " 'page_word_count': 445,\n",
       " 'page_sentences_count': 17,\n",
       " 'page_tokens_count': 706.0,\n",
       " 'text': 'Efﬁcient Estimation of Word Representations in Vector Space Tomas Mikolov Google Inc., Mountain View, CA tmikolov@google.com Kai Chen Google Inc., Mountain View, CA kaichen@google.com Greg Corrado Google Inc., Mountain View, CA gcorrado@google.com Jeffrey Dean Google Inc., Mountain View, CA jeff@google.com Abstract We propose two novel model architectures for computing continuous vector repre- sentations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previ- ously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art perfor- mance on our test set for measuring syntactic and semantic word similarities. 1 Introduction Many current NLP systems and techniques treat words as atomic units - there is no notion of similar- ity between words, as these are represented as indices in a vocabulary. This choice has several good reasons - simplicity, robustness and the observation that simple models trained on huge amounts of data outperform complex systems trained on less data. An example is the popular N-gram model used for statistical language modeling - today, it is possible to train N-grams on virtually all available data (trillions of words [3]). However, the simple techniques are at their limits in many tasks. For example, the amount of relevant in-domain data for automatic speech recognition is limited - the performance is usually dominated by the size of high quality transcribed speech data (often just millions of words). In machine translation, the existing corpora for many languages contain only a few billions of words or less. Thus, there are situations where simple scaling up of the basic techniques will not result in any signiﬁcant progress, and we have to focus on more advanced techniques. With progress of machine learning techniques in recent years, it has become possible to train more complex models on much larger data set, and they typically outperform the simple models. Probably the most successful concept is to use distributed representations of words [10]. For example, neural network based language models signiﬁcantly outperform N-gram models [1, 27, 17]. 1.1 Goals of the Paper The main goal of this paper is to introduce techniques that can be used for learning high-quality word vectors from huge data sets with billions of words, and with millions of words in the vocabulary. As far as we know, none of the previously proposed architectures has been successfully trained on more 1 arXiv:1301.3781v3  [cs.CL]  7 Sep 2013'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d44b1391044644bc42cb043bb233f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for item in tqdm(pages_and_text):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "    item [\"sentences\"] =[str(sent) for sent in item[\"sentences\"]]\n",
    "    item[\"page_sentences_count\"] = len(item[\"sentences\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_num': 10,\n",
       "  'page_char_count': 3535,\n",
       "  'page_word_count': 528,\n",
       "  'page_sentences_count': 53,\n",
       "  'page_tokens_count': 883.75,\n",
       "  'text': '7 Follow-Up Work After the initial version of this paper was written, we published single-machine multi-threaded C++ code for computing the word vectors, using both the continuous bag-of-words and skip-gram archi- tectures4. The training speed is signiﬁcantly higher than reported earlier in this paper, i.e. it is in the order of billions of words per hour for typical hyperparameter choices. We also published more than 1.4 million vectors that represent named entities, trained on more than 100 billion words. Some of our follow-up work will be published in an upcoming NIPS 2013 paper [21]. References [1] Y. Bengio, R. Ducharme, P. Vincent. A neural probabilistic language model. Journal of Ma- chine Learning Research, 3:1137-1155, 2003. [2] Y. Bengio, Y. LeCun. Scaling learning algorithms towards AI. In: Large-Scale Kernel Ma- chines, MIT Press, 2007. [3] T. Brants, A. C. Popat, P. Xu, F. J. Och, and J. Dean. Large language models in machine translation. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Language Learning, 2007. [4] R. Collobert and J. Weston. A Uniﬁed Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning. In International Conference on Machine Learning, ICML, 2008. [5] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu and P. Kuksa. Natural Lan- guage Processing (Almost) from Scratch. Journal of Machine Learning Research, 12:2493- 2537, 2011. [6] J. Dean, G.S. Corrado, R. Monga, K. Chen, M. Devin, Q.V. Le, M.Z. Mao, M.A. Ranzato, A. Senior, P. Tucker, K. Yang, A. Y. Ng., Large Scale Distributed Deep Networks, NIPS, 2012. [7] J.C. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 2011. [8] J. Elman. Finding Structure in Time. Cognitive Science, 14, 179-211, 1990. [9] Eric H. Huang, R. Socher, C. D. Manning and Andrew Y. Ng. Improving Word Representations via Global Context and Multiple Word Prototypes. In: Proc. Association for Computational Linguistics, 2012. [10] G.E. Hinton, J.L. McClelland, D.E. Rumelhart. Distributed representations. In: Parallel dis- tributed processing: Explorations in the microstructure of cognition. Volume 1: Foundations, MIT Press, 1986. [11] D.A. Jurgens, S.M. Mohammad, P.D. Turney, K.J. Holyoak. Semeval-2012 task 2: Measuring degrees of relational similarity. In: Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), 2012. [12] A.L. Maas, R.E. Daly, P.T. Pham, D. Huang, A.Y. Ng, and C. Potts. Learning word vectors for sentiment analysis. In Proceedings of ACL, 2011. [13] T. Mikolov. Language Modeling for Speech Recognition in Czech, Masters thesis, Brno Uni- versity of Technology, 2007. [14] T. Mikolov, J. Kopeck´y, L. Burget, O. Glembek and J. ˇCernock´y. Neural network based lan- guage models for higly inﬂective languages, In: Proc. ICASSP 2009. [15] T. Mikolov, M. Karaﬁ´at, L. Burget, J. ˇCernock´y, S. Khudanpur. Recurrent neural network based language model, In: Proceedings of Interspeech, 2010. [16] T. Mikolov, S. Kombrink, L. Burget, J. ˇCernock´y, S. Khudanpur. Extensions of recurrent neural network language model, In: Proceedings of ICASSP 2011. [17] T. Mikolov, A. Deoras, S. Kombrink, L. Burget, J. ˇCernock´y. Empirical Evaluation and Com- bination of Advanced Language Modeling Techniques, In: Proceedings of Interspeech, 2011. 4The code is available at https://code.google.com/p/word2vec/ 11',\n",
       "  'sentences': ['7 Follow-Up Work After the initial version of this paper was written, we published single-machine multi-threaded C++ code for computing the word vectors, using both the continuous bag-of-words and skip-gram archi- tectures4.',\n",
       "   'The training speed is signiﬁcantly higher than reported earlier in this paper, i.e. it is in the order of billions of words per hour for typical hyperparameter choices.',\n",
       "   'We also published more than 1.4 million vectors that represent named entities, trained on more than 100 billion words.',\n",
       "   'Some of our follow-up work will be published in an upcoming NIPS 2013 paper [21].',\n",
       "   'References [1] Y. Bengio, R. Ducharme, P. Vincent.',\n",
       "   'A neural probabilistic language model.',\n",
       "   'Journal of Ma- chine Learning Research, 3:1137-1155, 2003. [',\n",
       "   '2] Y. Bengio, Y. LeCun.',\n",
       "   'Scaling learning algorithms towards AI.',\n",
       "   'In: Large-Scale Kernel Ma- chines, MIT Press, 2007. [',\n",
       "   '3] T. Brants, A. C. Popat, P. Xu, F. J. Och, and J. Dean.',\n",
       "   'Large language models in machine translation.',\n",
       "   'In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Language Learning, 2007. [',\n",
       "   '4] R. Collobert and J. Weston.',\n",
       "   'A Uniﬁed Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning.',\n",
       "   'In International Conference on Machine Learning, ICML, 2008. [',\n",
       "   '5] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu and P. Kuksa.',\n",
       "   'Natural Lan- guage Processing (Almost) from Scratch.',\n",
       "   'Journal of Machine Learning Research, 12:2493- 2537, 2011. [',\n",
       "   '6] J. Dean, G.S. Corrado, R. Monga, K. Chen, M. Devin, Q.V. Le, M.Z. Mao, M.A. Ranzato, A. Senior, P. Tucker, K. Yang, A. Y. Ng.,',\n",
       "   'Large Scale Distributed Deep Networks, NIPS, 2012. [',\n",
       "   '7] J.C. Duchi, E. Hazan, and Y. Singer.',\n",
       "   'Adaptive subgradient methods for online learning and stochastic optimization.',\n",
       "   'Journal of Machine Learning Research, 2011. [',\n",
       "   '8] J. Elman.',\n",
       "   'Finding Structure in Time.',\n",
       "   'Cognitive Science, 14, 179-211, 1990. [',\n",
       "   '9] Eric H. Huang, R. Socher, C. D. Manning and Andrew Y. Ng.',\n",
       "   'Improving Word Representations via Global Context and Multiple Word Prototypes.',\n",
       "   'In: Proc.',\n",
       "   'Association for Computational Linguistics, 2012. [',\n",
       "   '10] G.E. Hinton, J.L. McClelland, D.E. Rumelhart.',\n",
       "   'Distributed representations.',\n",
       "   'In: Parallel dis- tributed processing: Explorations in the microstructure of cognition.',\n",
       "   'Volume 1: Foundations, MIT Press, 1986. [',\n",
       "   '11] D.A. Jurgens, S.M. Mohammad, P.D. Turney, K.J. Holyoak.',\n",
       "   'Semeval-2012 task 2: Measuring degrees of relational similarity.',\n",
       "   'In: Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), 2012. [',\n",
       "   '12] A.L. Maas, R.E. Daly, P.T. Pham, D. Huang, A.Y. Ng, and C. Potts.',\n",
       "   'Learning word vectors for sentiment analysis.',\n",
       "   'In Proceedings of ACL, 2011. [',\n",
       "   '13] T. Mikolov.',\n",
       "   'Language Modeling for Speech Recognition in Czech, Masters thesis, Brno Uni- versity of Technology, 2007. [',\n",
       "   '14] T. Mikolov, J. Kopeck´y, L. Burget, O. Glembek and J. ˇCernock´y.',\n",
       "   'Neural network based lan- guage models for higly inﬂective languages, In: Proc.',\n",
       "   'ICASSP 2009. [',\n",
       "   '15] T. Mikolov, M. Karaﬁ´at, L. Burget, J. ˇCernock´y, S. Khudanpur.',\n",
       "   'Recurrent neural network based language model, In: Proceedings of Interspeech, 2010. [',\n",
       "   '16] T. Mikolov, S. Kombrink, L. Burget, J. ˇCernock´y, S. Khudanpur.',\n",
       "   'Extensions of recurrent neural network language model, In: Proceedings of ICASSP 2011. [',\n",
       "   '17] T. Mikolov, A. Deoras, S. Kombrink, L. Burget, J. ˇCernock´y.',\n",
       "   'Empirical Evaluation and Com- bination of Advanced Language Modeling Techniques, In: Proceedings of Interspeech, 2011.',\n",
       "   '4The code is available at https://code.google.com/p/word2vec/ 11']}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_text, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentences_count</th>\n",
       "      <th>page_tokens_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.50</td>\n",
       "      <td>3227.75</td>\n",
       "      <td>529.92</td>\n",
       "      <td>25.33</td>\n",
       "      <td>806.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.61</td>\n",
       "      <td>680.73</td>\n",
       "      <td>112.17</td>\n",
       "      <td>12.41</td>\n",
       "      <td>170.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2089.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>522.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.75</td>\n",
       "      <td>2788.00</td>\n",
       "      <td>483.25</td>\n",
       "      <td>19.25</td>\n",
       "      <td>697.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.50</td>\n",
       "      <td>3332.00</td>\n",
       "      <td>541.50</td>\n",
       "      <td>22.50</td>\n",
       "      <td>833.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.25</td>\n",
       "      <td>3860.25</td>\n",
       "      <td>598.25</td>\n",
       "      <td>24.25</td>\n",
       "      <td>965.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.00</td>\n",
       "      <td>3989.00</td>\n",
       "      <td>696.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>997.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  page_char_count  page_word_count  page_sentences_count  \\\n",
       "count     12.00            12.00            12.00                 12.00   \n",
       "mean       5.50          3227.75           529.92                 25.33   \n",
       "std        3.61           680.73           112.17                 12.41   \n",
       "min        0.00          2089.00           299.00                 11.00   \n",
       "25%        2.75          2788.00           483.25                 19.25   \n",
       "50%        5.50          3332.00           541.50                 22.50   \n",
       "75%        8.25          3860.25           598.25                 24.25   \n",
       "max       11.00          3989.00           696.00                 53.00   \n",
       "\n",
       "       page_tokens_count  \n",
       "count              12.00  \n",
       "mean              806.94  \n",
       "std               170.18  \n",
       "min               522.25  \n",
       "25%               697.00  \n",
       "50%               833.00  \n",
       "75%               965.06  \n",
       "max               997.25  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_text)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       " [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       " [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sentences_chunk_size = 10\n",
    "def split_list(input_list : list[str], \n",
    "               slice_size : int= num_sentences_chunk_size)-> list[list[str]]:\n",
    "    return [input_list[i:i+slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "test_list = list(range(50))\n",
    "split_list(input_list=test_list, slice_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6cb7ef85874b909b75c8fd46fdb09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm (pages_and_text):\n",
    "    item[\"sentences_chunks\"] = split_list(input_list=item[\"sentences\"], slice_size=num_sentences_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentences_chunks\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_num': 4,\n",
       "  'page_char_count': 2680,\n",
       "  'page_word_count': 549,\n",
       "  'page_sentences_count': 17,\n",
       "  'page_tokens_count': 670.0,\n",
       "  'text': 'w(t-2) w(t+1) w(t-1) w(t+2) w(t) SUM        INPUT         PROJECTION         OUTPUT w(t)           INPUT         PROJECTION      OUTPUT w(t-2) w(t-1) w(t+1) w(t+2)                    CBOW                                                   Skip-gram Figure 1: New model architectures. The CBOW architecture predicts the current word based on the context, and the Skip-gram predicts surrounding words given the current word. R words from the future of the current word as correct labels. This will require us to do R × 2 word classiﬁcations, with the current word as input, and each of the R + R words as output. In the following experiments, we use C = 10. 4 Results To compare the quality of different versions of word vectors, previous papers typically use a table showing example words and their most similar words, and understand them intuitively. Although it is easy to show that word France is similar to Italy and perhaps some other countries, it is much more challenging when subjecting those vectors in a more complex similarity task, as follows. We follow previous observation that there can be many different types of similarities between words, for example, word big is similar to bigger in the same sense that small is similar to smaller. Example of another type of relationship can be word pairs big - biggest and small - smallest [20]. We further denote two pairs of words with the same relationship as a question, as we can ask: ”What is the word that is similar to small in the same sense as biggest is similar to big?” Somewhat surprisingly, these questions can be answered by performing simple algebraic operations with the vector representation of words. To ﬁnd a word that is similar to small in the same sense as biggest is similar to big, we can simply compute vector X = vector(”biggest”)−vector(”big”)+ vector(”small”). Then, we search in the vector space for the word closest to X measured by cosine distance, and use it as the answer to the question (we discard the input question words during this search). When the word vectors are well trained, it is possible to ﬁnd the correct answer (word smallest) using this method. Finally, we found that when we train high dimensional word vectors on a large amount of data, the resulting vectors can be used to answer very subtle semantic relationships between words, such as a city and the country it belongs to, e.g. France is to Paris as Germany is to Berlin. Word vectors with such semantic relationships could be used to improve many existing NLP applications, such as machine translation, information retrieval and question answering systems, and may enable other future applications yet to be invented. 5',\n",
       "  'sentences': ['w(t-2) w(t+1) w(t-1) w(t+2) w(t) SUM        INPUT         PROJECTION         OUTPUT w(t)           INPUT         PROJECTION      OUTPUT w(t-2) w(t-1) w(t+1) w(t+2)                    CBOW                                                   Skip-gram Figure 1: New model architectures.',\n",
       "   'The CBOW architecture predicts the current word based on the context, and the Skip-gram predicts surrounding words given the current word.',\n",
       "   'R words from the future of the current word as correct labels.',\n",
       "   'This will require us to do R × 2 word classiﬁcations, with the current word as input, and each of the R + R words as output.',\n",
       "   'In the following experiments, we use C = 10.',\n",
       "   '4 Results To compare the quality of different versions of word vectors, previous papers typically use a table showing example words and their most similar words, and understand them intuitively.',\n",
       "   'Although it is easy to show that word France is similar to Italy and perhaps some other countries, it is much more challenging when subjecting those vectors in a more complex similarity task, as follows.',\n",
       "   'We follow previous observation that there can be many different types of similarities between words, for example, word big is similar to bigger in the same sense that small is similar to smaller.',\n",
       "   'Example of another type of relationship can be word pairs big - biggest and small - smallest [20].',\n",
       "   'We further denote two pairs of words with the same relationship as a question, as we can ask: ”What is the word that is similar to small in the same sense as biggest is similar to big?”',\n",
       "   'Somewhat surprisingly, these questions can be answered by performing simple algebraic operations with the vector representation of words.',\n",
       "   'To ﬁnd a word that is similar to small in the same sense as biggest is similar to big, we can simply compute vector X = vector(”biggest”)−vector(”big”)+ vector(”small”).',\n",
       "   'Then, we search in the vector space for the word closest to X measured by cosine distance, and use it as the answer to the question (we discard the input question words during this search).',\n",
       "   'When the word vectors are well trained, it is possible to ﬁnd the correct answer (word smallest) using this method.',\n",
       "   'Finally, we found that when we train high dimensional word vectors on a large amount of data, the resulting vectors can be used to answer very subtle semantic relationships between words, such as a city and the country it belongs to, e.g. France is to Paris as Germany is to Berlin.',\n",
       "   'Word vectors with such semantic relationships could be used to improve many existing NLP applications, such as machine translation, information retrieval and question answering systems, and may enable other future applications yet to be invented.',\n",
       "   '5'],\n",
       "  'sentences_chunks': [['w(t-2) w(t+1) w(t-1) w(t+2) w(t) SUM        INPUT         PROJECTION         OUTPUT w(t)           INPUT         PROJECTION      OUTPUT w(t-2) w(t-1) w(t+1) w(t+2)                    CBOW                                                   Skip-gram Figure 1: New model architectures.',\n",
       "    'The CBOW architecture predicts the current word based on the context, and the Skip-gram predicts surrounding words given the current word.',\n",
       "    'R words from the future of the current word as correct labels.',\n",
       "    'This will require us to do R × 2 word classiﬁcations, with the current word as input, and each of the R + R words as output.',\n",
       "    'In the following experiments, we use C = 10.',\n",
       "    '4 Results To compare the quality of different versions of word vectors, previous papers typically use a table showing example words and their most similar words, and understand them intuitively.',\n",
       "    'Although it is easy to show that word France is similar to Italy and perhaps some other countries, it is much more challenging when subjecting those vectors in a more complex similarity task, as follows.',\n",
       "    'We follow previous observation that there can be many different types of similarities between words, for example, word big is similar to bigger in the same sense that small is similar to smaller.',\n",
       "    'Example of another type of relationship can be word pairs big - biggest and small - smallest [20].',\n",
       "    'We further denote two pairs of words with the same relationship as a question, as we can ask: ”What is the word that is similar to small in the same sense as biggest is similar to big?”'],\n",
       "   ['Somewhat surprisingly, these questions can be answered by performing simple algebraic operations with the vector representation of words.',\n",
       "    'To ﬁnd a word that is similar to small in the same sense as biggest is similar to big, we can simply compute vector X = vector(”biggest”)−vector(”big”)+ vector(”small”).',\n",
       "    'Then, we search in the vector space for the word closest to X measured by cosine distance, and use it as the answer to the question (we discard the input question words during this search).',\n",
       "    'When the word vectors are well trained, it is possible to ﬁnd the correct answer (word smallest) using this method.',\n",
       "    'Finally, we found that when we train high dimensional word vectors on a large amount of data, the resulting vectors can be used to answer very subtle semantic relationships between words, such as a city and the country it belongs to, e.g. France is to Paris as Germany is to Berlin.',\n",
       "    'Word vectors with such semantic relationships could be used to improve many existing NLP applications, such as machine translation, information retrieval and question answering systems, and may enable other future applications yet to be invented.',\n",
       "    '5']],\n",
       "  'num_chunks': 2}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_text, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentences_count</th>\n",
       "      <th>page_tokens_count</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.50</td>\n",
       "      <td>3227.75</td>\n",
       "      <td>529.92</td>\n",
       "      <td>25.33</td>\n",
       "      <td>806.94</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.61</td>\n",
       "      <td>680.73</td>\n",
       "      <td>112.17</td>\n",
       "      <td>12.41</td>\n",
       "      <td>170.18</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2089.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>522.25</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.75</td>\n",
       "      <td>2788.00</td>\n",
       "      <td>483.25</td>\n",
       "      <td>19.25</td>\n",
       "      <td>697.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.50</td>\n",
       "      <td>3332.00</td>\n",
       "      <td>541.50</td>\n",
       "      <td>22.50</td>\n",
       "      <td>833.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.25</td>\n",
       "      <td>3860.25</td>\n",
       "      <td>598.25</td>\n",
       "      <td>24.25</td>\n",
       "      <td>965.06</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.00</td>\n",
       "      <td>3989.00</td>\n",
       "      <td>696.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>997.25</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  page_char_count  page_word_count  page_sentences_count  \\\n",
       "count     12.00            12.00            12.00                 12.00   \n",
       "mean       5.50          3227.75           529.92                 25.33   \n",
       "std        3.61           680.73           112.17                 12.41   \n",
       "min        0.00          2089.00           299.00                 11.00   \n",
       "25%        2.75          2788.00           483.25                 19.25   \n",
       "50%        5.50          3332.00           541.50                 22.50   \n",
       "75%        8.25          3860.25           598.25                 24.25   \n",
       "max       11.00          3989.00           696.00                 53.00   \n",
       "\n",
       "       page_tokens_count  num_chunks  \n",
       "count              12.00       12.00  \n",
       "mean              806.94        3.08  \n",
       "std               170.18        1.24  \n",
       "min               522.25        2.00  \n",
       "25%               697.00        2.00  \n",
       "50%               833.00        3.00  \n",
       "75%               965.06        3.00  \n",
       "max               997.25        6.00  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_text)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d71ff29ef254e3c8008f2379a0b108b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_text):\n",
    "    for sentence_chunk in item[\"sentences_chunks\"]:\n",
    "        chunk_dict ={}\n",
    "        chunk_dict[\"page_num\"] = item[\"page_num\"]\n",
    "        joined_sentences_chunk = \" \".join(sentence_chunk).replace(\" \", \" \").strip()\n",
    "        joined_sentences_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentences_chunk)\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentences_chunk\n",
    "\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentences_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len(joined_sentences_chunk.split(\" \"))\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentences_chunk)/4\n",
    "\n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_num': 4,\n",
       "  'sentence_chunk': 'Somewhat surprisingly, these questions can be answered by performing simple algebraic operations with the vector representation of words. To ﬁnd a word that is similar to small in the same sense as biggest is similar to big, we can simply compute vector X = vector(”biggest”)−vector(”big”)+ vector(”small”). Then, we search in the vector space for the word closest to X measured by cosine distance, and use it as the answer to the question (we discard the input question words during this search). When the word vectors are well trained, it is possible to ﬁnd the correct answer (word smallest) using this method. Finally, we found that when we train high dimensional word vectors on a large amount of data, the resulting vectors can be used to answer very subtle semantic relationships between words, such as a city and the country it belongs to, e.g. France is to Paris as Germany is to Berlin. Word vectors with such semantic relationships could be used to improve many existing NLP applications, such as machine translation, information retrieval and question answering systems, and may enable other future applications yet to be invented. 5',\n",
       "  'chunk_char_count': 1145,\n",
       "  'chunk_word_count': 188,\n",
       "  'chunk_token_count': 286.25}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>37.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.24</td>\n",
       "      <td>1047.68</td>\n",
       "      <td>173.38</td>\n",
       "      <td>261.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.68</td>\n",
       "      <td>655.85</td>\n",
       "      <td>111.97</td>\n",
       "      <td>163.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>454.00</td>\n",
       "      <td>69.00</td>\n",
       "      <td>113.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.00</td>\n",
       "      <td>916.00</td>\n",
       "      <td>151.00</td>\n",
       "      <td>229.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1662.00</td>\n",
       "      <td>283.00</td>\n",
       "      <td>415.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.00</td>\n",
       "      <td>2165.00</td>\n",
       "      <td>384.00</td>\n",
       "      <td>541.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count     37.00             37.00             37.00              37.00\n",
       "mean       6.24           1047.68            173.38             261.92\n",
       "std        3.68            655.85            111.97             163.96\n",
       "min        0.00              1.00              1.00               0.25\n",
       "25%        3.00            454.00             69.00             113.50\n",
       "50%        6.00            916.00            151.00             229.00\n",
       "75%       10.00           1662.00            283.00             415.50\n",
       "max       11.00           2165.00            384.00             541.25"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 0.25 | Text: 7\n",
      "Chunk token count: 7.75 | Text: The number of CPU cores is an 8\n"
     ]
    }
   ],
   "source": [
    "# filtering chunks \n",
    "min_token_length = 30\n",
    "min_token_length = 30\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(2).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_num': 0,\n",
       "  'sentence_chunk': 'Efﬁcient Estimation of Word Representations in Vector Space Tomas Mikolov Google Inc., Mountain View, CA tmikolov@google.com Kai Chen Google Inc., Mountain View, CA kaichen@google.com Greg Corrado Google Inc., Mountain View, CA gcorrado@google.com Jeffrey Dean Google Inc., Mountain View, CA jeff@google.com Abstract We propose two novel model architectures for computing continuous vector repre- sentations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previ- ously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art perfor- mance on our test set for measuring syntactic and semantic word similarities. 1 Introduction Many current NLP systems and techniques treat words as atomic units - there is no notion of similar- ity between words, as these are represented as indices in a vocabulary. This choice has several good reasons - simplicity, robustness and the observation that simple models trained on huge amounts of data outperform complex systems trained on less data. An example is the popular N-gram model used for statistical language modeling - today, it is possible to train N-grams on virtually all available data (trillions of words [3]). However, the simple techniques are at their limits in many tasks. For example, the amount of relevant in-domain data for automatic speech recognition is limited - the performance is usually dominated by the size of high quality transcribed speech data (often just millions of words). In machine translation, the existing corpora for many languages contain only a few billions of words or less.',\n",
       "  'chunk_char_count': 1908,\n",
       "  'chunk_word_count': 295,\n",
       "  'chunk_token_count': 477.0},\n",
       " {'page_num': 0,\n",
       "  'sentence_chunk': 'Thus, there are situations where simple scaling up of the basic techniques will not result in any signiﬁcant progress, and we have to focus on more advanced techniques. With progress of machine learning techniques in recent years, it has become possible to train more complex models on much larger data set, and they typically outperform the simple models. Probably the most successful concept is to use distributed representations of words [10]. For example, neural network based language models signiﬁcantly outperform N-gram models [1, 27, 17]. 1.1 Goals of the Paper The main goal of this paper is to introduce techniques that can be used for learning high-quality word vectors from huge data sets with billions of words, and with millions of words in the vocabulary. As far as we know, none of the previously proposed architectures has been successfully trained on more 1 arXiv:1301.3781v3  [cs. CL]  7 Sep 2013',\n",
       "  'chunk_char_count': 916,\n",
       "  'chunk_word_count': 151,\n",
       "  'chunk_token_count': 229.0}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_num': 5,\n",
       "  'sentence_chunk': 'Table 1: Examples of ﬁve types of semantic and nine types of syntactic questions in the Semantic- Syntactic Word Relationship test set. Type of relationship Word Pair 1 Word Pair 2 Common capital city Athens Greece Oslo Norway All capital cities Astana Kazakhstan Harare Zimbabwe Currency Angola kwanza Iran rial City-in-state Chicago Illinois Stockton California Man-Woman brother sister grandson granddaughter Adjective to adverb apparent apparently rapid rapidly Opposite possibly impossibly ethical unethical Comparative great greater tough tougher Superlative easy easiest lucky luckiest Present Participle think thinking read reading Nationality adjective Switzerland Swiss Cambodia Cambodian Past tense walking walked swimming swam Plural nouns mouse mice dollar dollars Plural verbs work works speak speaks 4.1 Task Description To measure quality of the word vectors, we deﬁne a comprehensive test set that contains ﬁve types of semantic questions, and nine types of syntactic questions. Two examples from each category are shown in Table 1. Overall, there are 8869 semantic and 10675 syntactic questions. The questions in each category were created in two steps: ﬁrst, a list of similar word pairs was created manually. Then, a large list of questions is formed by connecting two word pairs. For example, we made a list of 68 large American cities and the states they belong to, and formed about 2.5K questions by picking two word pairs at random. We have included in our test set only single token words, thus multi-word entities are not present (such as New York). We evaluate the overall accuracy for all question types, and for each question type separately (se- mantic, syntactic). Question is assumed to be correctly answered only if the closest word to the vector computed using the above method is exactly the same as the correct word in the question; synonyms are thus counted as mistakes.',\n",
       "  'chunk_char_count': 1907,\n",
       "  'chunk_word_count': 298,\n",
       "  'chunk_token_count': 476.75}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks_over_min_token_len, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedaya/git/RAG_model/Rag/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Requires !pip install sentence-transformers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m----> 3\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall-mpnet-base-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# choose the device to load the model to (note: GPU will often be *much* faster than CPU)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create a list of sentences to turn into numbers\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Sentences Transformers library provides an easy and open-source way to create embeddings.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentences can be embedded one by one or as a list of strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddings are one of the most powerful concepts in machine learning!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearn to use embeddings well and you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mll be well on your way to being an AI engineer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m ]\n",
      "File \u001b[0;32m~/git/RAG_model/Rag/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:214\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token)\u001b[0m\n\u001b[1;32m    211\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device_name()\n\u001b[1;32m    212\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse pytorch device_name: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device))\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault prompt name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in the configured prompts \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdictionary with keys \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m     )\n",
      "File \u001b[0;32m~/git/RAG_model/Rag/lib/python3.12/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/RAG_model/Rag/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/RAG_model/Rag/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/git/RAG_model/Rag/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/RAG_model/Rag/lib/python3.12/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/git/RAG_model/Rag/lib/python3.12/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Requires !pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=\"cuda\") # choose the device to load the model to (note: GPU will often be *much* faster than CPU)\n",
    "\n",
    "# Create a list of sentences to turn into numbers\n",
    "sentences = [\n",
    "    \"The Sentences Transformers library provides an easy and open-source way to create embeddings.\",\n",
    "    \"Sentences can be embedded one by one or as a list of strings.\",\n",
    "    \"Embeddings are one of the most powerful concepts in machine learning!\",\n",
    "    \"Learn to use embeddings well and you'll be well on your way to being an AI engineer.\"\n",
    "]\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embeddings_dict = dict(zip(sentences, embeddings))\n",
    "\n",
    "# See the embeddings\n",
    "for sentence, embedding in embeddings_dict.items():\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Yo! How cool are embeddings?\n",
      "Embedding:\n",
      "[-1.97448116e-02 -4.51077055e-03 -4.98486962e-03  6.55444860e-02\n",
      " -9.87674389e-03  2.72836108e-02  3.66426110e-02 -3.30219767e-03\n",
      "  8.50078650e-03  8.24952498e-03 -2.28497703e-02  4.02430147e-02\n",
      " -5.75200692e-02  6.33691847e-02  4.43207137e-02 -4.49506715e-02\n",
      "  1.25284614e-02 -2.52011847e-02 -3.55293006e-02  1.29559003e-02\n",
      "  8.67021922e-03 -1.92917790e-02  3.55635840e-03  1.89505480e-02\n",
      " -1.47128161e-02 -9.39848833e-03  7.64175924e-03  9.62184742e-03\n",
      " -5.98920882e-03 -3.90168726e-02 -5.47824651e-02 -5.67456335e-03\n",
      "  1.11644426e-02  4.08067517e-02  1.76319088e-06  9.15305596e-03\n",
      " -8.77257995e-03  2.39382870e-02 -2.32784245e-02  8.04999843e-02\n",
      "  3.19176875e-02  5.12598455e-03 -1.47708450e-02 -1.62525177e-02\n",
      " -6.03213124e-02 -4.35689688e-02  4.51211594e-02 -1.79053694e-02\n",
      "  2.63366792e-02 -3.47866528e-02 -8.89172778e-03 -5.47675341e-02\n",
      " -1.24372439e-02 -2.38606706e-02  8.33496898e-02  5.71241677e-02\n",
      "  1.13328267e-02 -1.49595067e-02  9.20377970e-02  2.72710025e-02\n",
      " -1.42185586e-02  1.91208981e-02  1.49963303e-02 -3.12198866e-02\n",
      "  8.99579152e-02  4.51188162e-02  2.58020535e-02 -5.51739102e-03\n",
      "  1.15909716e-02  4.72100899e-02 -1.51019190e-02  1.70818325e-02\n",
      " -7.22596981e-03  3.45763564e-02 -8.76465999e-03  5.22016846e-02\n",
      " -6.49008900e-02 -4.31378335e-02  6.36964813e-02  4.02881242e-02\n",
      " -1.99042782e-02  5.39059704e-03  1.28820529e-02 -4.81255502e-02\n",
      "  4.58800681e-02 -2.17094608e-02  1.89203694e-02 -3.46344374e-02\n",
      " -1.66456699e-02  7.65162846e-03 -2.26693675e-02 -1.96454227e-02\n",
      "  1.87632181e-02  1.01383040e-02  6.85412809e-02 -5.39850304e-03\n",
      " -3.38225579e-03  4.08412963e-02  4.98623997e-02 -1.16485534e-02\n",
      "  8.91738907e-02  4.02785838e-02 -3.64719215e-03  4.37758975e-02\n",
      " -2.96080597e-02 -5.53753832e-03 -2.00208891e-02 -2.01982595e-02\n",
      "  4.59849164e-02  2.29337290e-02 -5.37306331e-02 -3.19279172e-02\n",
      "  1.37536845e-03  6.25036359e-02 -2.18308680e-02 -6.43255934e-02\n",
      " -2.24791840e-02  3.31955217e-02 -3.12837772e-02  5.17936423e-02\n",
      " -2.84003261e-02  2.55067777e-02  3.36493775e-02  7.50668272e-02\n",
      " -4.46472317e-03 -4.87705469e-02 -7.35218897e-02 -5.46353199e-02\n",
      "  8.88524856e-03  2.95797866e-02 -9.95699130e-03 -6.32761279e-03\n",
      "  4.46259752e-02 -1.58483982e-02 -1.71330497e-02  3.36603001e-02\n",
      " -1.57665915e-03 -5.45971878e-02  2.91160922e-02 -2.80596036e-02\n",
      "  2.96793506e-02  5.12153134e-02  1.48765966e-02 -4.76487912e-02\n",
      "  1.26052313e-02  1.49851339e-03  1.33206481e-02 -2.82469429e-02\n",
      " -3.29254642e-02 -8.53569247e-03 -5.27607873e-02  7.29350299e-02\n",
      " -6.41821176e-02 -2.51785177e-03 -9.02637839e-03 -1.10469048e-03\n",
      "  1.57514382e-02  4.30823267e-02  1.12269474e-02 -3.54585350e-02\n",
      "  4.95163240e-02  1.21270753e-02  1.66343944e-03 -5.06922835e-03\n",
      " -1.11001981e-02 -8.66925716e-03 -3.26440036e-02 -3.98021601e-02\n",
      " -2.05970593e-02  1.09074460e-02 -6.62528276e-02  3.71707082e-02\n",
      " -3.74916568e-02 -3.24730650e-02  5.85900694e-02  8.48081112e-02\n",
      "  3.92413139e-02  3.15815173e-02  3.78386192e-02 -1.35472463e-02\n",
      "  5.95062524e-02  2.58904770e-02 -1.31900040e-02  6.30589649e-02\n",
      "  3.27136293e-02  6.92142686e-03 -1.42607335e-02  7.76676536e-02\n",
      " -1.16102919e-02 -3.66428010e-02 -2.83837840e-02  2.72279773e-02\n",
      "  2.49364488e-02 -4.22296487e-03 -3.63100693e-02 -2.04887725e-02\n",
      "  3.98861170e-02 -2.64726747e-02  4.41380590e-03 -5.19635379e-02\n",
      "  1.71031425e-05  4.81284857e-02  2.04450656e-02  9.84970033e-02\n",
      "  3.68267260e-02  1.53404567e-02  7.50978128e-04 -3.38638499e-02\n",
      " -2.69872826e-02  4.72444631e-02  4.56701554e-02 -3.49246487e-02\n",
      " -1.18770609e-02  3.45576694e-03 -6.32300740e-03 -4.78412546e-02\n",
      "  1.84098631e-02 -2.23157462e-02 -3.70727777e-02  5.87339625e-02\n",
      "  6.22731261e-03 -1.46716302e-02  7.29222819e-02  2.21960037e-03\n",
      " -6.53120056e-02  3.51679660e-02 -1.54901426e-02  6.01420999e-02\n",
      " -9.41001624e-03  2.81196851e-02 -1.12652015e-02  5.24159812e-04\n",
      "  1.01888627e-01 -5.69957457e-02 -3.52360681e-02 -5.20478189e-03\n",
      " -8.46638530e-03  1.39209256e-02  1.80780459e-02 -1.10493951e-01\n",
      "  5.13116606e-02 -4.36432101e-02  2.84142829e-02  9.55936499e-03\n",
      "  4.28096876e-02 -3.95833775e-02  5.25829196e-02  1.92814786e-02\n",
      "  3.44885583e-03 -1.76871512e-02  3.85699905e-02  6.92503573e-03\n",
      " -3.59440297e-02 -2.63612997e-02 -4.96697752e-03  4.24525589e-02\n",
      " -4.22464013e-02  3.45900049e-03  3.55866738e-02 -1.68201923e-02\n",
      "  3.54331844e-02  4.52805730e-03  6.46290975e-03 -2.17710938e-02\n",
      " -2.50032954e-02  1.41418697e-02  1.51257757e-02 -2.99570095e-02\n",
      " -3.94227579e-02  1.87821817e-02 -1.68784207e-03 -9.83500038e-04\n",
      " -3.26322019e-02  5.06563019e-03 -8.90461728e-03 -1.55095393e-02\n",
      "  1.87758375e-02 -4.52473201e-02 -1.72957368e-02  3.50973345e-02\n",
      "  1.33018205e-02  1.00633139e-02 -4.36593257e-02 -1.68618988e-02\n",
      " -1.91048421e-02  6.35489821e-02  8.08325410e-03 -1.02532730e-02\n",
      " -4.53626877e-03 -4.60835695e-02 -1.64704248e-02 -6.24686107e-03\n",
      "  2.58868579e-02 -6.39063939e-02 -7.82401394e-03 -2.36076415e-02\n",
      "  2.74617691e-02  5.80534860e-02 -3.40748765e-02  6.46012202e-02\n",
      "  2.00062506e-02 -2.14934926e-02  1.69361029e-02 -5.54070575e-03\n",
      " -2.40397546e-02  3.09444238e-02 -2.34439666e-03  3.02589443e-02\n",
      " -4.57217321e-02  2.00641155e-02 -2.57117227e-02 -1.13377406e-03\n",
      " -3.57524604e-02  6.92953467e-02  2.80848774e-03  3.58742177e-02\n",
      " -1.52722159e-02 -3.41523737e-02  1.80923473e-02  1.65400244e-02\n",
      "  1.31705850e-02 -6.36670925e-03  5.49302921e-02  8.47313832e-03\n",
      " -4.26077433e-02  2.17084587e-02 -4.89023477e-02  1.18851785e-04\n",
      "  5.16287647e-02  7.59220857e-04  1.59222875e-02 -1.61299706e-02\n",
      "  1.44981248e-02  2.19509210e-02  3.02651562e-02 -3.44151333e-02\n",
      " -4.80380096e-02 -3.71689945e-02  4.68194932e-02 -3.46219353e-02\n",
      "  4.74861532e-04 -4.34820950e-02 -1.80125143e-02 -6.44844398e-02\n",
      " -2.66967565e-02  3.63660902e-02 -3.76219675e-02 -1.64600983e-02\n",
      "  2.20248327e-02  2.16080312e-04  3.64510454e-02 -2.76135765e-02\n",
      " -5.87056717e-03  6.97318371e-03 -1.25863450e-03  2.12774165e-02\n",
      "  6.21470995e-03 -3.57214659e-02 -5.09366281e-02  2.85553224e-02\n",
      "  6.48822486e-02  3.45731415e-02 -2.57281270e-02  4.52561444e-03\n",
      " -4.63605747e-02  3.32225338e-02  1.69973925e-03 -1.29355500e-02\n",
      " -3.03734131e-02  1.23608978e-02 -3.17957747e-04  1.66231990e-02\n",
      "  1.04892189e-02  1.71540752e-02  1.88860409e-02 -3.62256467e-02\n",
      "  4.65737768e-02  2.17128210e-02  4.97535989e-02  3.03067546e-02\n",
      "  1.59914012e-03 -6.30024746e-02 -6.34594914e-03  1.07304622e-04\n",
      " -5.56749525e-03  2.37264968e-02 -8.38230271e-03  5.38897254e-02\n",
      " -9.08977017e-02 -1.37359872e-02  1.18454583e-02  3.37257539e-03\n",
      " -2.81855483e-02  1.56333228e-03  2.22415458e-02  6.21023960e-02\n",
      " -8.68119821e-02 -4.40635020e-03 -1.63995549e-02  1.69665273e-02\n",
      " -1.34548452e-02  3.00696120e-03 -2.14618240e-02 -2.09503789e-02\n",
      " -1.39877591e-02 -1.23850694e-02  5.39979152e-02  6.03614561e-02\n",
      "  2.52982210e-02 -1.29661456e-01 -1.08081467e-01 -4.15774900e-03\n",
      " -7.20272539e-03  2.75885276e-02  4.87622321e-02 -2.95970980e-02\n",
      " -4.32555042e-02  2.75215656e-02  1.35718873e-02  3.87699716e-02\n",
      "  2.42039673e-02 -2.70842165e-02  8.59166235e-02 -1.98402982e-02\n",
      " -2.26344205e-02 -6.24927804e-02 -1.56845022e-02  4.11566831e-02\n",
      "  1.66952405e-02  7.97291845e-02 -3.24839242e-02  1.46561884e-03\n",
      " -3.27906273e-02  6.44815490e-02  2.09739413e-02 -7.56986067e-02\n",
      " -1.31789874e-03  2.24045897e-03 -6.60841586e-03 -6.84251785e-02\n",
      " -5.36860572e-03  6.55136183e-02  5.45558985e-03  1.58993863e-02\n",
      " -2.18052231e-02  2.16424419e-03  4.72954288e-03 -7.25655705e-02\n",
      " -1.59349740e-02 -1.05623305e-02  2.70786788e-02  1.93766574e-03\n",
      " -4.45123315e-02  2.89783385e-02  2.43084226e-02 -1.73885785e-02\n",
      " -3.80669758e-02 -3.06799151e-02 -3.24778259e-02 -4.33339184e-04\n",
      "  2.55846083e-02  2.70478483e-02 -1.72519751e-04 -4.93688567e-04\n",
      " -7.12094754e-02  5.69768772e-02  6.61400855e-02 -3.87268104e-02\n",
      " -1.30683519e-02  1.00663211e-02 -2.17740331e-02  1.92212239e-02\n",
      "  7.66691146e-03 -3.86652574e-02 -1.66108645e-02 -3.41467746e-02\n",
      " -1.04185315e-02  1.75906308e-02 -1.23776542e-02 -1.68433841e-02\n",
      " -2.40113102e-02  4.70198505e-03  4.88461461e-03  4.73663509e-02\n",
      "  4.34111953e-02 -8.08343571e-03 -2.48272233e-02 -1.93978269e-02\n",
      " -3.16525102e-02 -1.56419035e-02 -7.79948430e-03  1.28888441e-02\n",
      "  2.61943396e-02  3.65819340e-03  5.79228774e-02  5.43151647e-02\n",
      " -5.05586788e-02  1.78927090e-03 -2.45471150e-02 -2.47595999e-02\n",
      "  3.60356877e-03  1.94152240e-02 -4.23822924e-02 -1.86907277e-02\n",
      "  2.32945494e-02 -3.17982435e-02 -2.60645691e-02 -5.40362298e-03\n",
      " -3.82069871e-02  2.21719909e-02  1.33360280e-02  5.58054484e-02\n",
      " -3.57716866e-02 -3.54791656e-02  1.27723301e-02  6.80177063e-02\n",
      "  5.37152812e-02  2.54151784e-02 -1.16638504e-02 -1.07512977e-02\n",
      " -9.74432100e-03  7.20507465e-03  9.21899080e-03 -4.73684780e-02\n",
      " -3.89389903e-03  3.11453529e-02  3.62331979e-02 -1.65902935e-02\n",
      " -3.63394991e-02  1.95634607e-02 -2.15058494e-02 -7.04767322e-03\n",
      "  9.13175754e-03 -4.05358896e-02 -3.67076248e-02  1.16995938e-01\n",
      "  1.17913887e-01  8.00502896e-02 -1.61983129e-02 -2.00733747e-02\n",
      " -5.54062016e-02 -7.22410306e-02  2.14558002e-02 -4.46405145e-04\n",
      " -1.42903179e-02  8.35540146e-03  3.34207676e-02  1.42891202e-02\n",
      "  4.62512635e-02 -3.53420191e-02  1.68673266e-02 -2.99732201e-03\n",
      " -5.44997007e-02 -4.80719730e-02  9.47561057e-04 -6.29721507e-33\n",
      " -2.30286438e-02 -2.51128357e-02 -5.35218976e-02 -2.09470019e-02\n",
      " -6.79717492e-03 -4.64015529e-02 -4.49633691e-03  1.65114887e-02\n",
      " -1.12677794e-02  1.33013809e-02 -1.72552820e-02 -1.96653586e-02\n",
      "  5.53236343e-03  1.02775376e-02  9.47373686e-04 -2.24022288e-02\n",
      "  5.30364849e-02  7.77775934e-03 -9.48474091e-03  2.25515869e-02\n",
      " -4.34495928e-03  2.25208756e-02  1.98086575e-02 -7.57428482e-02\n",
      " -4.36680904e-03  2.50829905e-02  2.59393696e-02 -3.07077561e-02\n",
      "  7.04764351e-02  8.63500684e-02 -7.75880739e-02  1.59991533e-02\n",
      " -5.04692420e-02  4.88355197e-02  3.74992355e-03 -6.12926669e-04\n",
      " -3.87277901e-02 -2.32235119e-02 -3.63983437e-02 -5.07016154e-03\n",
      "  1.10517768e-02 -3.26515660e-02  3.68386693e-02 -4.54948992e-02\n",
      " -1.18526642e-03  1.92688184e-03  2.18783580e-02  2.71092802e-02\n",
      " -4.06264216e-02  6.99159801e-02 -7.33282045e-02 -8.15295149e-03\n",
      " -1.42555609e-02  3.78038781e-03  1.20974362e-01 -6.68213218e-02\n",
      "  3.05051152e-02  1.24480613e-02 -4.59293984e-02  1.03873098e-02\n",
      " -3.97978052e-02 -1.33042196e-02 -1.59402415e-02 -4.29347157e-02\n",
      "  4.05275710e-02  7.07073808e-02 -4.50928546e-02 -3.62474471e-02\n",
      " -1.87588781e-02  1.60928648e-02  2.12657135e-02  6.70025423e-02\n",
      "  3.25864181e-02  1.51125938e-02  3.20371501e-02 -1.35436170e-02\n",
      "  2.31779981e-02 -1.13125844e-02  1.23795634e-02 -3.73516977e-02\n",
      "  1.55545224e-03  2.15824582e-02 -3.49442437e-02 -2.97690742e-02\n",
      "  2.32397411e-02 -1.25703337e-02 -1.09432973e-02 -8.87968689e-02\n",
      " -2.20183991e-02 -1.18423048e-02 -5.71083613e-02  3.91810127e-02\n",
      " -1.98827125e-02 -5.59270494e-02  7.60342227e-03  2.23641824e-02\n",
      " -1.86267253e-02  3.79805267e-02 -8.79652449e-04 -5.26199490e-02\n",
      "  2.05068011e-03  1.72814839e-02 -4.84028980e-02 -1.87740419e-02\n",
      "  1.91171608e-07  2.06594449e-02  3.03575210e-02  5.71851479e-03\n",
      " -5.33938222e-02 -2.46520881e-02  1.80340782e-02 -3.39978002e-02\n",
      "  3.46113593e-05 -6.40035793e-02  2.50049569e-02 -2.04111841e-02\n",
      " -2.72037974e-03 -3.55961695e-02  2.71923114e-02  6.48940206e-02\n",
      "  9.83432983e-04 -4.38490510e-02 -4.45297174e-02 -7.44889490e-03\n",
      "  1.15205254e-02 -2.91254069e-03 -2.15494987e-02  2.84254062e-03\n",
      "  4.29398939e-02 -6.09041229e-02 -7.86320306e-03 -3.90126230e-03\n",
      "  2.47718305e-07  7.75886059e-04  7.47737065e-02  1.99318118e-03\n",
      " -6.07220875e-03  3.69210728e-02  2.78421324e-02 -5.64900041e-02\n",
      "  1.61058903e-02 -9.50827170e-03 -2.60848785e-03 -2.45737229e-02\n",
      "  1.91390775e-02  5.08195609e-02  2.61258744e-02 -1.03838101e-01\n",
      " -3.05815265e-02 -3.53345163e-02 -4.07038108e-02 -2.19843015e-02\n",
      " -2.24092193e-02  5.05567454e-02  7.22607598e-02  5.54789975e-02\n",
      "  4.89434041e-02  3.37949395e-03 -6.84760064e-02  7.10320659e-03\n",
      "  3.15671461e-03  4.78091799e-02 -7.19795078e-02 -3.30301970e-02\n",
      "  3.19158584e-02  1.76431192e-03 -4.62790132e-02 -1.96378492e-02\n",
      "  1.67493820e-02  4.73603830e-02 -2.09441632e-02  7.10244663e-03\n",
      "  4.53146063e-02 -4.76523638e-02 -4.74881381e-02  1.00799864e-02\n",
      " -8.39594007e-02  3.36930230e-02 -3.72189060e-02  1.19432965e-02\n",
      " -3.16896290e-02 -1.29724119e-03 -1.55541236e-02  1.81727745e-02\n",
      " -1.49368513e-02 -1.70671456e-02 -4.19716686e-02  3.94660467e-03\n",
      " -2.24302057e-02  2.07292736e-02 -4.61415686e-02  8.50217510e-03\n",
      " -2.56864522e-02 -1.65337678e-02 -1.51846372e-02 -1.00041572e-02\n",
      "  2.19642837e-02  2.61104815e-02  7.31359124e-02 -1.83709543e-02\n",
      "  1.93979481e-34 -7.27934530e-03  5.96488127e-03  4.44310270e-02\n",
      "  4.14822660e-02  1.12916902e-02 -1.93217508e-02  4.41879369e-02\n",
      " -8.93792044e-03  3.61120030e-02 -5.52125759e-02 -2.89572161e-02]\n",
      "Embedding size: (768,)\n"
     ]
    }
   ],
   "source": [
    "single_sentence = \"Yo! How cool are embeddings?\"\n",
    "single_embedding = embedding_model.encode(single_sentence)\n",
    "print(f\"Sentence: {single_sentence}\")\n",
    "print(f\"Embedding:\\n{single_embedding}\")\n",
    "print(f\"Embedding size: {single_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaae5fa700b1413abc3e91778853acd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.75 s, sys: 88.7 ms, total: 4.84 s\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Uncomment to see how long it takes to create embeddings on CPU\n",
    "# # Make sure the model is on the CPU\n",
    "embedding_model.to(\"cuda\")\n",
    "\n",
    "# # Embed each chunk one by one\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 33.6 ms, total: 1.23 s\n",
      "Wall time: 967 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0256,  0.0618, -0.0207,  ...,  0.0152, -0.0724, -0.0116],\n",
       "        [ 0.0281,  0.0947,  0.0167,  ...,  0.0169, -0.0640, -0.0098],\n",
       "        [ 0.0251,  0.0787, -0.0355,  ...,  0.0039, -0.0431, -0.0091],\n",
       "        ...,\n",
       "        [ 0.0368,  0.0113, -0.0195,  ...,  0.0389, -0.0790, -0.0214],\n",
       "        [ 0.0403, -0.0096, -0.0302,  ...,  0.0145, -0.0164,  0.0017],\n",
       "        [ 0.0582,  0.0196, -0.0367,  ...,  0.0020, -0.0951,  0.0262]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]\n",
    "# Embed all texts in batches\n",
    "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
    "                                               batch_size=32, # you can use different batch sizes here for speed/performance, I found 32 works well for this use case\n",
    "                                               convert_to_tensor=True) # optional to return embeddings as tensor instead of array\n",
    "\n",
    "text_chunk_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Efﬁcient Estimation of Word Representations in...</td>\n",
       "      <td>1908</td>\n",
       "      <td>295</td>\n",
       "      <td>477.00</td>\n",
       "      <td>[ 2.55730599e-02  6.18023090e-02 -2.07428038e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Thus, there are situations where simple scalin...</td>\n",
       "      <td>916</td>\n",
       "      <td>151</td>\n",
       "      <td>229.00</td>\n",
       "      <td>[ 2.80693397e-02  9.46570039e-02  1.66562535e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>than a few hundred of millions of words, with ...</td>\n",
       "      <td>1875</td>\n",
       "      <td>302</td>\n",
       "      <td>468.75</td>\n",
       "      <td>[ 2.50720680e-02  7.86750689e-02 -3.55245918e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>This work has been followed by many others. An...</td>\n",
       "      <td>1582</td>\n",
       "      <td>248</td>\n",
       "      <td>395.50</td>\n",
       "      <td>[ 3.95338275e-02  4.53573354e-02 -9.83004645e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Similar to [18], to compare different model ar...</td>\n",
       "      <td>518</td>\n",
       "      <td>58</td>\n",
       "      <td>129.50</td>\n",
       "      <td>[ 1.91809684e-02  4.63378504e-02  3.54503118e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_num                                     sentence_chunk  \\\n",
       "0         0  Efﬁcient Estimation of Word Representations in...   \n",
       "1         0  Thus, there are situations where simple scalin...   \n",
       "2         1  than a few hundred of millions of words, with ...   \n",
       "3         1  This work has been followed by many others. An...   \n",
       "4         1  Similar to [18], to compare different model ar...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0              1908               295             477.00   \n",
       "1               916               151             229.00   \n",
       "2              1875               302             468.75   \n",
       "3              1582               248             395.50   \n",
       "4               518                58             129.50   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 2.55730599e-02  6.18023090e-02 -2.07428038e-...  \n",
       "1  [ 2.80693397e-02  9.46570039e-02  1.66562535e-...  \n",
       "2  [ 2.50720680e-02  7.86750689e-02 -3.55245918e-...  \n",
       "3  [ 3.95338275e-02  4.53573354e-02 -9.83004645e-...  \n",
       "4  [ 1.91809684e-02  4.63378504e-02  3.54503118e-...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret 'torch.float32' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m text_chunks_and_embedding_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_chunks_and_embeddings_df.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m text_chunks_and_embedding_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m text_chunks_and_embedding_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mfromstring(x\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m\"\u001b[39m), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 10\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_chunks_and_embedding_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m pages_and_chunks \u001b[38;5;241m=\u001b[39m text_chunks_and_embedding_df_load\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m text_chunks_and_embedding_df\n",
      "File \u001b[0;32m~/git/RAG_model/Rag/lib/python3.12/site-packages/numpy/core/shape_base.py:456\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    454\u001b[0m sl \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m),) \u001b[38;5;241m*\u001b[39m axis \u001b[38;5;241m+\u001b[39m (_nx\u001b[38;5;241m.\u001b[39mnewaxis,)\n\u001b[1;32m    455\u001b[0m expanded_arrays \u001b[38;5;241m=\u001b[39m [arr[sl] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret 'torch.float32' as a data type"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "embeddings = torch.tensor(np.stack(text_chunks_and_embedding_df[\"embedding\"].tolist(), axis=0, dtype=torch.float32)).to(device)\n",
    "pages_and_chunks = text_chunks_and_embedding_df_load.to_dict(orient=\"records\")\n",
    "text_chunks_and_embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [0.0255730599, 0.061802309, -0.0207428038, 0.0...\n",
       "1     [0.0280693397, 0.0946570039, 0.0166562535, 0.0...\n",
       "2     [0.025072068, 0.0786750689, -0.0355245918, 0.0...\n",
       "3     [0.0395338275, 0.0453573354, -0.00983004645, 0...\n",
       "4     [0.0191809684, 0.0463378504, 0.00354503118, 0....\n",
       "5     [0.0485486723, 0.00419945177, -0.0124799153, 0...\n",
       "6     [0.0358137302, 0.0119810989, -0.00490031438, 0...\n",
       "7     [0.0126892757, 0.0221281461, 0.003916563, 0.01...\n",
       "8     [0.038186986, 0.0740807578, 0.00408044411, 0.0...\n",
       "9     [0.0635828972, 0.0334105715, -0.000616335368, ...\n",
       "10    [0.0422829241, 0.00571635878, -0.0269344933, 0...\n",
       "11    [0.0333030708, 0.0686960369, -0.0220683441, 0....\n",
       "12    [0.0525155663, 0.0377974063, -0.0232448988, 0....\n",
       "13    [0.033879146, 0.054509446, -0.0479785539, 0.04...\n",
       "14    [0.0553145409, 0.0262890533, 0.003137514, 0.05...\n",
       "15    [0.0149881076, 0.0469476469, 0.00904379878, 0....\n",
       "16    [0.0495093204, 0.0382961072, -0.0243331715, 0....\n",
       "17    [0.0510549024, 0.0681468174, -0.00147661718, 0...\n",
       "18    [0.0401144549, 0.0487548187, -0.0135470321, 0....\n",
       "19    [0.0672734976, 0.0565817915, 0.00116962299, 0....\n",
       "20    [0.0535832681, 0.0666219294, -0.0107166814, 0....\n",
       "21    [0.0336519964, 0.0721614361, -0.0308629293, 0....\n",
       "22    [0.0446699299, 0.084857516, 0.0283198673, 0.07...\n",
       "23    [0.0518483035, 0.079782553, -0.0105490386, 0.0...\n",
       "24    [0.0290100183, 0.0520930998, -0.00422079908, 0...\n",
       "25    [0.0309064724, 0.0208178665, -0.0224905144, 0....\n",
       "26    [0.0256880186, 0.0306312405, -0.00826501474, 0...\n",
       "27    [0.0411561392, 0.0171403494, -0.0363544486, 0....\n",
       "28    [0.0253061391, -0.00842827093, 0.00592957437, ...\n",
       "29    [0.040359389, 0.0306442194, -0.0132930586, 0.0...\n",
       "30    [0.037480928, 0.0405935533, -0.00243717828, 0....\n",
       "31    [0.0501310453, 0.0217178669, -0.0163118858, 0....\n",
       "32    [0.0368010625, 0.0112781469, -0.0195011254, 0....\n",
       "33    [0.0403466038, -0.0096459724, -0.0301790386, 0...\n",
       "34    [0.05819536, 0.0196463633, -0.0367021486, 0.05...\n",
       "Name: embedding, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df[\"embedding\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.stack(text_chunks_and_embedding_df[\"embedding\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 768)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedaya/git/RAG_model/Rag/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util , SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected m1 and m2 to have the same dtype, but got: float != double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m perf_counter \u001b[38;5;28;01mas\u001b[39;00m timer\n\u001b[1;32m      7\u001b[0m start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[0;32m----> 8\u001b[0m dot_scores \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m end_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/git/RAG_model/Rag/lib/python3.12/site-packages/sentence_transformers/util.py:72\u001b[0m, in \u001b[0;36mdot_score\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(b\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     70\u001b[0m     b \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: float != double"
     ]
    }
   ],
   "source": [
    "query = \"ArithmeticError: integer division or modulo by zero\" \n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "\n",
    "from time import perf_counter as timer\n",
    " \n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(query_embedding, b=embeddings)[0]\n",
    "end_time = timer()\n",
    "print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
    "top_results_dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 6 GB\n"
     ]
    }
   ],
   "source": [
    "# Get GPU available memory\n",
    "import torch\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
    "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2813bd3acbd743e5b183bf5cac292bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6baf6f7b816c49978699702762adf36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page_num': 6,\n",
       "  'text': '3. Create and personalize analyses based on the fund and industry 11/27/24, 7:56 AM Keye: Automated Due Diligence for Private Market Investors | Y Combinator https://www.ycombinator.com/companies/keye 7/9',\n",
       "  'pages_token_count': 51.0,\n",
       "  'sentences': [3.,\n",
       "   Create and personalize analyses based on the fund and industry 11/27/24, 7:56 AM Keye: Automated Due Diligence for Private Market Investors | Y Combinator https://www.ycombinator.com/companies/keye 7/9],\n",
       "  'sentence_count': ['3.',\n",
       "   'Create and personalize analyses based on the fund and industry 11/27/24, 7:56 AM Keye: Automated Due Diligence for Private Market Investors | Y Combinator https://www.ycombinator.com/companies/keye 7/9']}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "import spacy\n",
    "import random\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"\n",
    "    This function is used to format the text extracted from the pdf files.\n",
    "    \"\"\"\n",
    "    text_clean = text.replace(\"\\n\", \" \").strip()\n",
    "    return text_clean\n",
    "\n",
    "def open_read_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_text = []\n",
    "    for page_num in tqdm(range(len(doc))):\n",
    "        page = doc[page_num]\n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text=text)\n",
    "\n",
    "        pages_text.append({\n",
    "            \"page_num\": page_num,\n",
    "            \"text\": text,\n",
    "            \"pages_token_count\": len(text)/4\n",
    "        }) \n",
    "    return pages_text\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "pages_text = open_read_pdf(\"Keyee_data.pdf\")\n",
    "\n",
    "for item in tqdm(pages_text):\n",
    "    doc = nlp(item[\"text\"])\n",
    "    item[\"sentences\"] = list(doc.sents)\n",
    "    item[\"sentence_count\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "\n",
    "\n",
    "random_page = random.sample(pages_text, k=1)\n",
    "random_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e348bb23aac0409097af0b275d1b2d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_sentence_chunk_size = 10 \n",
    "\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list: list, \n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
    "\n",
    "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_text):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bf146f9b074134af050d3eaf83918c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_text):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        \n",
    "        \n",
    "        # Convert Span objects to strings before joining\n",
    "        joined_sentence_chunk = \"\".join(str(sentence) for sentence in sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo \n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# How many chunks do we have?\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>674.36</td>\n",
       "      <td>99.50</td>\n",
       "      <td>168.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>533.98</td>\n",
       "      <td>79.79</td>\n",
       "      <td>133.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>138.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>34.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>296.75</td>\n",
       "      <td>38.50</td>\n",
       "      <td>74.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>515.00</td>\n",
       "      <td>69.00</td>\n",
       "      <td>128.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>921.75</td>\n",
       "      <td>147.25</td>\n",
       "      <td>230.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2073.00</td>\n",
       "      <td>285.00</td>\n",
       "      <td>518.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count             14.00             14.00              14.00\n",
       "mean             674.36             99.50             168.59\n",
       "std              533.98             79.79             133.50\n",
       "min              138.00             16.00              34.50\n",
       "25%              296.75             38.50              74.19\n",
       "50%              515.00             69.00             128.75\n",
       "75%              921.75            147.25             230.44\n",
       "max             2073.00            285.00             518.25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedaya/git/RAG_model/Rag/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/vedaya/git/RAG_model/Rag/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > 5].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]\n",
    "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.08 s, sys: 112 ms, total: 1.19 s\n",
      "Wall time: 1.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0680,  0.0956, -0.0205,  ..., -0.0103, -0.0222, -0.0358],\n",
       "        [ 0.0402,  0.0532, -0.0179,  ..., -0.0130,  0.0405, -0.0633],\n",
       "        [ 0.0433,  0.0459, -0.0174,  ..., -0.0072,  0.0487, -0.0410],\n",
       "        ...,\n",
       "        [ 0.0513,  0.0229, -0.0332,  ...,  0.0121,  0.0166, -0.0205],\n",
       "        [ 0.0633,  0.0468, -0.0334,  ...,  0.0213, -0.0021, -0.0362],\n",
       "        [ 0.0745,  0.1126, -0.0310,  ..., -0.0070,  0.0280, -0.0187]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Embed all texts in batches\n",
    "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
    "                                               batch_size=32, # you can use different batch sizes here for speed/performance, I found 32 works well for this use case\n",
    "                                               convert_to_tensor=True) # optional to return embeddings as tensor instead of array\n",
    "\n",
    "text_chunk_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08e8b1314f14dc5b183d1e62be550d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.7 s, sys: 12.8 ms, total: 1.71 s\n",
      "Wall time: 260 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Send the model to the GPU\n",
    "embedding_model.to(\"cuda\") # requires a GPU installed, for reference on my local machine, I'm using a NVIDIA RTX 4090\n",
    "\n",
    "# Create embeddings one by one on the GPU\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"keyee_data_text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About What Happens at YC?ApplyYC Interview Gui...</td>\n",
       "      <td>2073</td>\n",
       "      <td>285</td>\n",
       "      <td>518.25</td>\n",
       "      <td>[ 6.80441409e-02  9.55673158e-02 -2.05079056e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jobs at Keye View all jobs → Software Engineer...</td>\n",
       "      <td>289</td>\n",
       "      <td>49</td>\n",
       "      <td>72.25</td>\n",
       "      <td>[ 4.02226895e-02  5.31646535e-02 -1.78571604e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keye Founded:2024 Team Size:3 Location:New Yor...</td>\n",
       "      <td>1271</td>\n",
       "      <td>210</td>\n",
       "      <td>317.75</td>\n",
       "      <td>[ 4.33278494e-02  4.58828509e-02 -1.74414366e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Working through 2 historical SaaS acquisitions...</td>\n",
       "      <td>1014</td>\n",
       "      <td>148</td>\n",
       "      <td>253.50</td>\n",
       "      <td>[ 6.43678904e-02  5.44376075e-02 -2.38667727e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keye_Unlock your Due Diligence Process ɦ min ɦ...</td>\n",
       "      <td>721</td>\n",
       "      <td>108</td>\n",
       "      <td>180.25</td>\n",
       "      <td>[ 4.16762084e-02  7.27907717e-02 -2.13617925e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sentence_chunk  chunk_char_count  \\\n",
       "0  About What Happens at YC?ApplyYC Interview Gui...              2073   \n",
       "1  Jobs at Keye View all jobs → Software Engineer...               289   \n",
       "2  Keye Founded:2024 Team Size:3 Location:New Yor...              1271   \n",
       "3  Working through 2 historical SaaS acquisitions...              1014   \n",
       "4  Keye_Unlock your Due Diligence Process ɦ min ɦ...               721   \n",
       "\n",
       "   chunk_word_count  chunk_token_count  \\\n",
       "0               285             518.25   \n",
       "1                49              72.25   \n",
       "2               210             317.75   \n",
       "3               148             253.50   \n",
       "4               108             180.25   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 6.80441409e-02  9.55673158e-02 -2.05079056e-...  \n",
       "1  [ 4.02226895e-02  5.31646535e-02 -1.78571604e-...  \n",
       "2  [ 4.33278494e-02  4.58828509e-02 -1.74414366e-...  \n",
       "3  [ 6.43678904e-02  5.44376075e-02 -2.38667727e-...  \n",
       "4  [ 4.16762084e-02  7.27907717e-02 -2.13617925e-...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 768])\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"keyee_data_text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "pages_chunk =  text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
    "\n",
    "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About What Happens at YC?ApplyYC Interview Gui...</td>\n",
       "      <td>2073</td>\n",
       "      <td>285</td>\n",
       "      <td>518.25</td>\n",
       "      <td>[0.0680441409, 0.0955673158, -0.0205079056, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jobs at Keye View all jobs → Software Engineer...</td>\n",
       "      <td>289</td>\n",
       "      <td>49</td>\n",
       "      <td>72.25</td>\n",
       "      <td>[0.0402226895, 0.0531646535, -0.0178571604, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keye Founded:2024 Team Size:3 Location:New Yor...</td>\n",
       "      <td>1271</td>\n",
       "      <td>210</td>\n",
       "      <td>317.75</td>\n",
       "      <td>[0.0433278494, 0.0458828509, -0.0174414366, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Working through 2 historical SaaS acquisitions...</td>\n",
       "      <td>1014</td>\n",
       "      <td>148</td>\n",
       "      <td>253.50</td>\n",
       "      <td>[0.0643678904, 0.0544376075, -0.0238667727, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keye_Unlock your Due Diligence Process ɦ min ɦ...</td>\n",
       "      <td>721</td>\n",
       "      <td>108</td>\n",
       "      <td>180.25</td>\n",
       "      <td>[0.0416762084, 0.0727907717, -0.0213617925, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sentence_chunk  chunk_char_count  \\\n",
       "0  About What Happens at YC?ApplyYC Interview Gui...              2073   \n",
       "1  Jobs at Keye View all jobs → Software Engineer...               289   \n",
       "2  Keye Founded:2024 Team Size:3 Location:New Yor...              1271   \n",
       "3  Working through 2 historical SaaS acquisitions...              1014   \n",
       "4  Keye_Unlock your Due Diligence Process ɦ min ɦ...               721   \n",
       "\n",
       "   chunk_word_count  chunk_token_count  \\\n",
       "0               285             518.25   \n",
       "1                49              72.25   \n",
       "2               210             317.75   \n",
       "3               148             253.50   \n",
       "4               108             180.25   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0680441409, 0.0955673158, -0.0205079056, -0...  \n",
       "1  [0.0402226895, 0.0531646535, -0.0178571604, -0...  \n",
       "2  [0.0433278494, 0.0458828509, -0.0174414366, -0...  \n",
       "3  [0.0643678904, 0.0544376075, -0.0238667727, -0...  \n",
       "4  [0.0416762084, 0.0727907717, -0.0213617925, -0...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedaya/git/RAG_model/Rag/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=\"cuda\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: founder of keyee\n",
      "14  Time taken: 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.6823, 0.5301, 0.4732, 0.4542, 0.4532], device='cuda:0'),\n",
       "indices=tensor([ 2,  1, 12,  6,  5], device='cuda:0'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"founder of keyee\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "from time import perf_counter as timer\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(query_embedding, b=embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"{len(embeddings)}  Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
    "top_results_dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'founder of keyee'\n",
      "\n",
      "Results:\n",
      "Score: 0.6823\n",
      "Text: \n",
      "Keye Founded:2024 Team Size:3 Location:New York Group Partner:Garry Tan    \n",
      "Active Founders Rohan Parikh, Founder Co-Founder & CEO at Keye, Rohan has over\n",
      "6+ yrs in investment banking, spanning front-office roles across IB and Global\n",
      "Markets. Within 5 years, he was promoted to Director, where he drove a 7x\n",
      "increase in deal flow and revenue. Previously, he worked as a management\n",
      "consultant with Accenture before transitioning to Standard & Poor’s credit\n",
      "division in finance. Rohan holds an MBA from Wharton, complemented by a\n",
      "technical background with a Master's in Financial Engg. &B. Eng degree Rohan\n",
      "Parikh Keye   Conor Brown, Founder Conor is a Co-Founder and the Chief Operating\n",
      "Officer of Keye. Before co-founding Keye, Conor co-founded SecureFlow, a funds\n",
      "flow and deal insights platform for M&A, while earning an MBA from The Wharton\n",
      "School. He has also held key roles as an investor at Vista Equity Partners and\n",
      "an investment banker at Goldman Sachs. He attended Amherst College for his BA,\n",
      "where he also captained the hockey team. Conor Brown Keye   Lalit Lal,\n",
      "Cofounder, CTO Lalit is a Cofounder and CTO at Keye. By trade, Lalit is a\n",
      "seasoned software engineer with a over 7 years in industry experience leading\n",
      "and building SaaS products from the ground up.\n",
      "Page number: {'sentence_chunk': \"Keye Founded:2024 Team Size:3 Location:New York Group Partner:Garry Tan \\xa0\\xa0\\xa0 Active Founders Rohan Parikh, Founder Co-Founder & CEO at Keye, Rohan has over 6+ yrs in investment banking, spanning front-office roles across IB and Global Markets. Within 5 years, he was promoted to Director, where he drove a 7x increase in deal flow and revenue. Previously, he worked as a management consultant with Accenture before transitioning to Standard & Poor’s credit division in finance. Rohan holds an MBA from Wharton, complemented by a technical background with a Master's in Financial Engg. &B. Eng degree Rohan Parikh Keye \\xa0 Conor Brown, Founder Conor is a Co-Founder and the Chief Operating Officer of Keye. Before co-founding Keye, Conor co-founded SecureFlow, a funds flow and deal insights platform for M&A, while earning an MBA from The Wharton School. He has also held key roles as an investor at Vista Equity Partners and an investment banker at Goldman Sachs. He attended Amherst College for his BA, where he also captained the hockey team. Conor Brown Keye \\xa0 Lalit Lal, Cofounder, CTO Lalit is a Cofounder and CTO at Keye. By trade, Lalit is a seasoned software engineer with a over 7 years in industry experience leading and building SaaS products from the ground up.\", 'chunk_char_count': 1271, 'chunk_word_count': 210, 'chunk_token_count': 317.75}\n",
      "\n",
      "\n",
      "Score: 0.5301\n",
      "Text: \n",
      "Jobs at Keye View all jobs → Software Engineer New York, NY, US / NC, US /\n",
      "Toronto, ON, CA / Remote (US; CA) $80K - $200K Any (new grads ok) Apply Now\n",
      "11/27/24, 7:56 AM Keye: Automated Due Diligence for Private Market Investors | Y\n",
      "Combinator https://www.ycombinator.com/companies/keye 1/9\n",
      "Page number: {'sentence_chunk': 'Jobs at Keye View all jobs → Software Engineer New York, NY, US / NC, US / Toronto, ON, CA / Remote (US; CA) $80K - $200K Any (new grads ok) Apply Now 11/27/24, 7:56 AM Keye: Automated Due Diligence for Private Market Investors | Y Combinator https://www.ycombinator.com/companies/keye 1/9', 'chunk_char_count': 289, 'chunk_word_count': 49, 'chunk_token_count': 72.25}\n",
      "\n",
      "\n",
      "Score: 0.4732\n",
      "Text: \n",
      "Follow our journey: 🌐 Website: https://keye.co 💼 LinkedIn:\n",
      "https://www.linkedin.com/company/keye ✍ Capital AI blog:\n",
      "https://www.keye.co/blog 🐦 X: https://x.com/keye_co Company Photo 11/27/24, 7:56\n",
      "AM Keye: Automated Due Diligence for Private Market Investors | Y Combinator\n",
      "https://www.ycombinator.com/companies/keye 8/9\n",
      "Page number: {'sentence_chunk': 'Follow our journey: 🌐 Website: https://keye.co 💼 LinkedIn: https://www.linkedin.com/company/keye ✍ Capital AI blog: https://www.keye.co/blog 🐦 X: https://x.com/keye_co Company Photo 11/27/24, 7:56 AM Keye: Automated Due Diligence for Private Market Investors | Y Combinator https://www.ycombinator.com/companies/keye 8/9', 'chunk_char_count': 320, 'chunk_word_count': 35, 'chunk_token_count': 80.0}\n",
      "\n",
      "\n",
      "Score: 0.4542\n",
      "Text: \n",
      "11/27/24, 7:56 AM Keye: Automated Due Diligence for Private Market Investors | Y\n",
      "Combinator https://www.ycombinator.com/companies/keye 5/9\n",
      "Page number: {'sentence_chunk': '11/27/24, 7:56 AM Keye: Automated Due Diligence for Private Market Investors | Y Combinator https://www.ycombinator.com/companies/keye 5/9', 'chunk_char_count': 138, 'chunk_word_count': 16, 'chunk_token_count': 34.5}\n",
      "\n",
      "\n",
      "Score: 0.4532\n",
      "Text: \n",
      "11/27/24, 7:56 AM Keye: Automated Due Diligence for Private Market Investors | Y\n",
      "Combinator https://www.ycombinator.com/companies/keye 4/9\n",
      "Page number: {'sentence_chunk': '11/27/24, 7:56 AM Keye: Automated Due Diligence for Private Market Investors | Y Combinator https://www.ycombinator.com/companies/keye 4/9', 'chunk_char_count': 138, 'chunk_word_count': 16, 'chunk_token_count': 34.5}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Results:\")\n",
    "# Loop through zipped together scores and indicies from torch.topk\n",
    "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    print(\"Text: \")\n",
    "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
    "    print(f\"Page number: {pages_and_chunks[idx]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_resources(query: str,\n",
    "                                embeddings: torch.tensor,\n",
    "                                model: SentenceTransformer=embedding_model,\n",
    "                                n_resources_to_return: int=5,\n",
    "                                print_time: bool=True):\n",
    "    \"\"\"\n",
    "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query, \n",
    "                                   convert_to_tensor=True) \n",
    "\n",
    "    # Get dot product scores on embeddings\n",
    "    start_time = timer()\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "    end_time = timer()\n",
    "\n",
    "    if print_time:\n",
    "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "    scores, indices = torch.topk(input=dot_scores, \n",
    "                                 k=n_resources_to_return)\n",
    "\n",
    "    return scores, indices\n",
    "\n",
    "def print_top_results_and_scores(query: str,\n",
    "                                 embeddings: torch.tensor,\n",
    "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
    "                                 n_resources_to_return: int=5):\n",
    "    \"\"\"\n",
    "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
    "\n",
    "    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
    "    \"\"\"\n",
    "    \n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings,\n",
    "                                                  n_resources_to_return=n_resources_to_return)\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"Results:\")\n",
    "    # Loop through zipped together scores and indicies\n",
    "    for score, index in zip(scores, indices):\n",
    "        print(f\"Score: {score:.4f}\")\n",
    "        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
    "        # Print the page number too so we can reference the textbook further and check the results\n",
    "\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 14 embeddings: 0.00009 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.1974, 0.1681, 0.1598, 0.1529, 0.1502], device='cuda:0'),\n",
       " tensor([ 2, 11,  3, 13,  5], device='cuda:0'))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Rohan Parikh\"\n",
    "\n",
    "# Get just the scores and indices of top related results\n",
    "scores, indices =retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 14 embeddings: 0.00004 seconds.\n",
      "Query: Rohan Parikh\n",
      "\n",
      "Results:\n",
      "Score: 0.1974\n",
      "Keye Founded:2024 Team Size:3 Location:New York Group Partner:Garry Tan    \n",
      "Active Founders Rohan Parikh, Founder Co-Founder & CEO at Keye, Rohan has over\n",
      "6+ yrs in investment banking, spanning front-office roles across IB and Global\n",
      "Markets. Within 5 years, he was promoted to Director, where he drove a 7x\n",
      "increase in deal flow and revenue. Previously, he worked as a management\n",
      "consultant with Accenture before transitioning to Standard & Poor’s credit\n",
      "division in finance. Rohan holds an MBA from Wharton, complemented by a\n",
      "technical background with a Master's in Financial Engg. &B. Eng degree Rohan\n",
      "Parikh Keye   Conor Brown, Founder Conor is a Co-Founder and the Chief Operating\n",
      "Officer of Keye. Before co-founding Keye, Conor co-founded SecureFlow, a funds\n",
      "flow and deal insights platform for M&A, while earning an MBA from The Wharton\n",
      "School. He has also held key roles as an investor at Vista Equity Partners and\n",
      "an investment banker at Goldman Sachs. He attended Amherst College for his BA,\n",
      "where he also captained the hockey team. Conor Brown Keye   Lalit Lal,\n",
      "Cofounder, CTO Lalit is a Cofounder and CTO at Keye. By trade, Lalit is a\n",
      "seasoned software engineer with a over 7 years in industry experience leading\n",
      "and building SaaS products from the ground up.\n",
      "\n",
      "\n",
      "Score: 0.1681\n",
      "Principal/Vice President @ PE Funds, who wants to retain top talent and do more\n",
      "deals.3. CTO/CIO at Mega Funds, looking for innovative solutions to help\n",
      "investment teams.4. AI Steering Committee Members at Upper Middle Market/Mega\n",
      "Funds.5. Senior Associate looking to do more critical analyses and less pivot\n",
      "table permutations.6. Operating Partners (Tech-Focused) at Lower-Middle Market\n",
      "and Middle-Market Funds. We suggest you book some time here!\n",
      "\n",
      "\n",
      "Score: 0.1598\n",
      "Working through 2 historical SaaS acquisitions as an early engineer and leading\n",
      "technical teams of various sizes, Lalit is comfortable across the stack (devops,\n",
      "frontend, backend, and ML). He comes from a background in Robotics (University\n",
      "of Waterloo) and Machine Learning (University of Toronto). Lalit Lal Keye  \n",
      "Company Launches Keye🗝: The Smartest Private Equity Analyst TL;DR: Keye AI 🗝\n",
      "helps Private Equity Investors do due diligence for acquisitions more accurately\n",
      "and faster — in seconds rather than weeks. Unlike other tools that stop at\n",
      "summarizing, Keye creates all complex analyses relevant in diligence like\n",
      "cohort, retention, etc. It extracts critical insights from each of those\n",
      "analyses and assembles these insights into a holistic understanding of a\n",
      "business. With Keye, investors save time, make better investments, do more\n",
      "deals, and see superior returns.11/27/24, 7:56 AM Keye: Automated Due Diligence\n",
      "for Private Market Investors | Y Combinator\n",
      "https://www.ycombinator.com/companies/keye 2/9\n",
      "\n",
      "\n",
      "Score: 0.1529\n",
      "Footer Y Combinator Programs YC Program Startup School Work at a Startup Co-\n",
      "Founder Matching Company YC Blog Contact Press People Careers Privacy Policy\n",
      "Notice at Collection Security Terms of Use Resources Startup Directory Startup\n",
      "Library Investors SAFE Hacker News Launch YC YC Deals Make something people\n",
      "want. Apply Twitter Facebook Instagram LinkedIn Youtube © 2024 Y Combinator\n",
      "11/27/24, 7:56 AM Keye: Automated Due Diligence for Private Market Investors | Y\n",
      "Combinator https://www.ycombinator.com/companies/keye 9/9\n",
      "\n",
      "\n",
      "Score: 0.1502\n",
      "11/27/24, 7:56 AM Keye: Automated Due Diligence for Private Market Investors | Y\n",
      "Combinator https://www.ycombinator.com/companies/keye 4/9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_results_and_scores(query=query,\n",
    "                             embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
